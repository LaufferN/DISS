<!doctype html>
<html>
    <head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>DISS</title>

	<link rel="stylesheet" href="dist/reset.css">
	<link rel="stylesheet" href="dist/reveal.css">
	<link rel="stylesheet" href="dist/theme/black.css">
        <link rel="stylesheet" href="style.css">

	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="plugin/highlight/monokai.css">
    </head>
    <body>
	<div class="reveal">
	    <div class="slides">
		<section id="title">
                    <h1>Demonstration Informed Specification Search</h1>
                    <h2 style="opacity: 0.9">A Maximum Entropy Approach</h2>
                    <figure style="opacity: 1" data-id="1">
                        <img data-id="2" style="height: 10em;" src='imgs/episodic_learning2.svg'>
                    </figure>
 
                    <h3 style="opacity: 0.95">Marcell Vazquez-Chanlatte</h3>

                    <div style="opacity: 0.7; margin: 1em">
                    <h4 style="font-size: 0.7em;">PhD Candidate at UC Berkeley</h4>
                    <ul>

                   <li style="font-size">Slides: <a href="https://mjvc.me/DISS">mjvc.me/DISS</a></li>

                    <li style="font-size">Code: <a href="https://github.com/mvcisback/DISS">github.com/mvcisback/DISS</a></li>
                    </ul>
                    </div>

                    <footer style="font-size: 0.65em; opacity: 0.5; width: 45em; text-align: left; margin-top: 1.5em">
                        Joint work with Ameesh Shah, Gil Lederman, and Sanjit A. Seshia
                    </footer>
              </section>

                <section data-auto-animate class="structure-of-talk">
                  <h1>Structure of the talk</h1>
                  <div>
                    <h2 style="text-align: center" data-id="0">
                      Specification motivated agents
                    </h2>
                      <img style="height: 5em;" src="imgs/episodic_learning2.svg"/>
                  </div>
                  <div style="opacity: 0.1">
                    <h2 data-id="1" >From demonstrations to specifications </h2>
                  </div>
                  <div style="opacity: 0.1">
                      <h2 data-id="2">Likelihood Calculation in Symbolic MDPs </h2>
                  </div>
                  <div style="opacity: 0.1">
                    <h2 data-id="3"> Conclusion and future work</h2>
                  </div>
                  <footer style="font-size: 0.7em; text-align: left">
                            <cite style="opacity: 0.7; font-size: 0.85em; color: white">
                                "Learning Task Specifications from
                                Demonstrations." NeurIPS `18. 
                            </cite>
                            <br>
                            <cite style="opacity: 0.7; font-size: 0.85em; color: #70ff70">
                                "Maximum Causal Entropy
                                Specification Inference from
                                Demonstrations." CAV `20
                            </cite>
                             <br>
                            <cite style="opacity: 0.7; font-size: 0.85em; color: cyan">
                                 "Entropy Guided Control
                                Improvisation", RSS `21
 
                            </cite>
 
                  </footer>
                </section>

                <section data-auto-animate class="structure-of-talk">
                  <h1>Structure of the talk</h1>
                  <div style="opacity: 0.5">
                    <h2 style="text-align: center" data-id="0">
                      Specification motivated agents
                    </h2>
                      <img style="height: 5em;" src="imgs/episodic_learning2.svg"/>
                  </div>
                  <div>
                    <h2 data-id="1" >From demonstrations to specifications </h2>
                  </div>
                  <div style="opacity: 0.1">
                      <h2 data-id="2">Likelihood Calculation in Symbolic MDPs </h2>
                  </div>
                  <div style="opacity: 0.1">
                    <h2 data-id="3"> Conclusion and future work</h2>
                  </div>
                  <footer style="font-size: 0.7em; text-align: left">
                            <cite style="opacity: 0.7; font-size: 0.85em; color: white">
                                "Learning Task Specifications from
                                Demonstrations." NeurIPS `18. 
                            </cite>
                            <br> 

                            <cite style="opacity: 0.7; font-size: 0.85em; color: #e5acff">
                                "Demonstration Informed Specification Search." In progress.
                            </cite>
                  </footer>
               </section>

                <section data-auto-animate class="structure-of-talk">
                  <h1>Structure of the talk</h1>
                  <div style="opacity: 0.5">
                    <h2 style="text-align: center" data-id="0">
                      Specification motivated agents
                    </h2>
                      <img style="height: 5em;" src="imgs/episodic_learning2.svg"/>
                  </div>
                  <div style="opacity: 0.5">
                    <h2 data-id="1" >From demonstrations to specifications </h2>
                  </div>
                  <div>
                      <h2 data-id="2">Likelihood Calculation in Symbolic MDPs </h2>
                  </div>
 
                  <div style="opacity: 0.1">
                    <h2 data-id="3"> Conclusion and future work</h2>
                  </div>

                  <footer style="font-size: 0.7em; text-align: left">
                            <cite style="opacity: 0.7; font-size: 0.85em; color: yellow">
                                "A
                                Model Counter's Guide to Probabilistic
                                Systems.". (preprint)
                            </cite>

 
                            <br>
                            <cite style="opacity: 0.7; font-size: 0.85em; color: orange">

                                "Model Checking Finite-Horizon Markov
                                Chains with Probabilistic Inference",
                                CAV `21
                            </cite>

                            <br> 
                            <cite style="opacity: 0.7; font-size: 0.85em; color: #70ff70">
                                "Maximum Causal Entropy
                                Specification Inference from
                                Demonstrations." CAV `20
                            </cite>
                             <br>
                            <cite style="opacity: 0.7; font-size: 0.85em; color: cyan">
                                 "Entropy Guided Control
                                Improvisation", RSS `21
                            </cite>
 
                  </footer>
                </section>

                <section data-auto-animate class="structure-of-talk">
                  <h1>Structure of the talk</h1>
                  <div style="opacity: 0.5">
                    <h2 style="text-align: center" data-id="0">
                      Specification motivated agents
                    </h2>
                      <img style="height: 5em;" src="imgs/episodic_learning2.svg"/>
                  </div>
                  <div style="opacity: 0.5">
                    <h2 data-id="1" >From demonstrations to specifications </h2>
                  </div>
                  <div style="opacity: 0.5">
                      <h2 data-id="2">Likelihood Calculation in Symbolic MDPs </h2>
                  </div>
 
                  <div>
                    <h2 data-id="3"> Conclusion and future work</h2>
                  </div>
                </section>


               <section>
                   <h1>Many important domains benefit from goal inference.</h1>
                    <img data-id="3"
                         style="height: 22em;"
                         src="imgs/intent_inference_apps.svg"/>
               </section>

                <section class="communication" data-auto-animate>
                    <h1>
                        Partial Communication through actions
                    </h1>
                    <figure data-id="1">
                        <img data-id="2" style="height: 12em" class='cartoon' src='imgs/episodic_learning2.svg'>
                    </figure>
                </section>
                <section class="communication">
                    <h1 style="opacity: 0.3">
                        Partial Communication through actions
                    </h1>
                    <figure data-id="1" style="opacity: 0.1">
                        <img data-id="2" style="height: 12em" src='imgs/episodic_learning_still.svg'>
                    </figure>
                    <ol style="font-size: 1.1em; margin-top: 1em;" >
                        <li>
                            Legible actions can be incredibly diagnostic.
                            <br>
                            <cite style="opacity: 0.6; font-size: 0.7em">
                                Dragan, et al, "Legibility and predictability of robot motion." HRI `13.</cite>
                        </li>
                        <li class="fragment">Actions influence other agents.
                            <br>
                             <cite style="opacity: 0.6; font-size: 0.7em">
                           
Sadigh, et al. "Planning for autonomous cars that leverage effects on human actions." RSS `16.
                            </cite>
                        </li>

                        <li class="fragment">
                            Essential for interpreting other signals: <span style="font-size: 0.8em">(Language, Disengagments, Other agents)</span>
                            <br>
                            
                            <cite style="opacity: 0.6; font-size: 0.7em">
                                 Goodman, et al. "Pragmatic language interpretation as probabilistic inference." TiCS `16
                            </cite>
                            <br>
                             <cite style="opacity: 0.6; font-size: 0.7em">
McPherson, et al. "Modeling supervisor safe sets for improving collaboration in human-robot teams." IROS `18
                            </cite>
 
                            <br>
                             <cite style="opacity: 0.6; font-size: 0.7em">
Afolabi, et al. "People as sensors: Imputing maps from human actions." IROS `18.
                            </cite>
 
                        </li>
                    </ol>
                </section>
		<section class="motivating-question">

                      Consider an agent acting in the following
                      stochastic grid world.
                    </h1>
 
                    <img data-id="3"
                         style="height: 20em;"
                         src="imgs/enter_lava_augmented_1.svg"/>
               </section>
		<section class="motivating-question">
                    <h1>
                        Can try to move up, down, left, right
                    </h1>
 
                    <img data-id="3"
                         style="height: 20em;"
                         src="imgs/enter_lava_augmented_2.svg"/>
               </section>
	
		<section data-auto-animate class="motivating-question">
                    <h1>
                        May slip due to wind
                    </h1>
 
                    <img data-id="3"
                         style="height: 20em;"
                         src="imgs/enter_lava_augmented_3.svg"/>
               </section>
	

		<section data-auto-animate class="motivating-question">
                    <h1>
                        What is the agent trying to do?
                    </h1>
 
                    <img data-id="3"
                         style="height: 20em;"
                         src="imgs/enter_lava_augmented.svg"/>
               </section>
               <section>
                    <h1>
                        Probably avoiding <span style="color: #ff8b8bff;">red</span> tiles
                    </h1>
 
                    <img data-id="3"
                         style="height: 20em;"
                         src="imgs/enter_lava_augmented_4.svg"/>
               </section>
               <section>
                    <h1>
                        Probably trying to reach <span style="color: #ffff00ff;">yellow</span> tiles
                    </h1>
 
                    <img data-id="3"
                         style="height: 20em;"
                         src="imgs/enter_lava_augmented_5.svg"/>
               </section>
                <section class="communication" data-auto-animate>
                    <h1>
                        Useful properties for an intent/goal formalism
                    </h1>

                    <img data-id="3"
                         style="height: 8em; opacity: 0.3"
                         src="imgs/enter_lava_augmented_5.svg"/>
 

                    <ol style="font-size: 1.3em; margin-top: 1em;">
                        <li class="fragment" style="margin-top: 0.4em;">Support composition.</li>
                        <li class="fragment" style="margin-top: 0.4em;">Be semantically robust to changes in the dynamics.</li>
                        <li class="fragment" style="margin-top: 0.4em;">Support describing temporal tasks.</li> 

                    </ol>
                </section>
                <section class="communication" data-auto-animate>
                    <h1>
                        Start with an example to motivate the first two
                    </h1>

                    <img data-id="3"
                         style="height: 8em; opacity: 0.3"
                         src="imgs/enter_lava_augmented_5.svg"/>
 

                    <ol style="font-size: 1.3em; margin-top: 1em;">
                        <li style="margin-top: 0.4em;">Support composition.</li>
                        <li style="margin-top: 0.4em;">Be semantically robust to changes in the dynamics.</li>
                        <li style="margin-top: 0.4em; opacity: 0.2">Support describing temporal tasks.</li> 

                    </ol>
                </section>


                <section id="rewards1">
                    <h1>How to safely compose in a dynamics invariant way?</h1>
                    <img src="imgs/reward_compose.png"/>
                    <p class="fragment">Proposal: Formalize around Boolean specifications.</p>
                    <p class="fragment">Will consider: Automata and Temporal Logic</p>

                </section>

                <section id="running-example-revisited">
                    <h1>Support boolean compositions</h1>
                    <img src="imgs/example_domain_1.svg"/>
               </section>

                <section id="running-example-revisited">
                    <h1>Support incremental learning</h1>
                    <img src="imgs/example_domain_1_2.svg"/>
               </section>

                <section class="communication" data-auto-animate>
                    <h1 style="opacity: 0.6">
                        Useful properties for an intent/goal formalism
                    </h1>

                    <img data-id="3"
                         style="height: 8em; opacity: 0.3"
                         src="imgs/enter_lava_augmented_5.svg"/>
 

                    <ol style="font-size: 1.3em; margin-top: 1em;">
                        <li style="margin-top: 0.4em; opacity: 0.3">Support composition.</li>
                        <li style="margin-top: 0.4em; opacity: 0.3">Be semantically robust to changes in the dynamics.</li>
                        <li style="margin-top: 0.4em;">Support describing temporal tasks.</li> 
                    </ol>
                </section>


                <section id="rewards2">
                    <h1>Dynamic States ≠ Reward States</h1>
                    <img src="imgs/reward_markov.png"/>
                    <p>
                        Beware the curse of history <cite style="font-size: 0.8em; opacity: 0.7">(Pineau et al 2003)</cite>.
                    </p>
                    <p class="fragment">
                        Naïvely adding history results in exponential state space explosion!
                    </p>
                    <p class="fragment">How to infer what history is important?</p>
                </section>

                <section>
                    <h1>Don't need "wet" to describe dynamics</h1>
                    <img src="imgs/example_domain_2.svg"/>
               </section>

                <section>
                    <h1>Can learn as state machine over state colors</h1>
                    <img src="imgs/example_domain_2_1.svg"/>
               </section>

                <section class="communication" data-auto-animate>
                    <h1 >
                        Will explore inferring goals as Boolean specifications
                    </h1>

                    <figure data-id="1">
                        <img data-id="2" style="height: 12em" class='cartoon' src='imgs/episodic_learning3.svg'>
                    </figure>
 

                    <ol style="font-size: 1.3em; margin-top: 1em;">
                        <li style="margin-top: 0.4em; ">Support composition.</li>
                        <li style="margin-top: 0.4em; ">Be semantically robust to changes in the dynamics.</li>
                        <li style="margin-top: 0.4em; ">Support describing temporal tasks.</li> 
                    </ol>
                </section>

                <section data-auto-animate class="structure-of-talk">
                  <h1>Structure of the talk</h1>
                  <div>
                    <h2 style="text-align: center" data-id="0">
                      Specification motivated agents
                    </h2>
                      <img style="height: 5em;" src="imgs/episodic_learning2.svg"/>
                  </div>
                  <div style="opacity: 0.1">
                    <h2 data-id="1" >From demonstrations to specifications </h2>
                  </div>
                  <div style="opacity: 0.1">
                      <h2 data-id="2">Likelihood Calculation in Symbolic MDPs </h2>
                  </div>
                  <div style="opacity: 0.1">
                    <h2 data-id="3"> Conclusion and future work</h2>
                  </div>
                  <footer style="font-size: 0.7em; text-align: left">
                            <cite style="opacity: 0.7; font-size: 0.85em; color: white">
                                "Learning Task Specifications from
                                Demonstrations." NeurIPS `18. 
                            </cite>
                            <br>
                            <cite style="opacity: 0.7; font-size: 0.85em; color: #70ff70">
                                "Maximum Causal Entropy
                                Specification Inference from
                                Demonstrations." CAV `20
                            </cite>
                             <br>
                            <cite style="opacity: 0.7; font-size: 0.85em; color: cyan">
                                 "Entropy Guided Control
                                Improvisation", RSS `21
 
                            </cite>
 
                  </footer>
                </section>
                <!-- ================ Basic Definitions ============================= -->
                
                <section data-auto-animate  class="task-specs-1">
                    <!-- Formal Methods Perspective -->
                    <h1>Dynamics Model</h1>
                    <ol>                    
                        <li data-id="1">
                            <span data-id="2">Assume some fixed sets of <dfn>states</dfn> and <dfn>actions</dfn>.</span>
                            <div>
                                <img class="fragment cartoon" src="imgs/gridworld.svg"/>
                                <img class="fragment cartoon" src="imgs/mdp.svg"/>
                            </div>
                        </li>
                        <li data-id="3" class="fragment">
                            A <dfn>trace</dfn>, $\xi$, is a sequence of states and actions.
                        </li>
                        <li class="fragment">Assume all traces the same length, \(\tau \in \mathbb{N}\).</li>
                </section>

                <section data-auto-animate class="task-specs-1">
                    <!-- Formal Methods Perspective -->
                    <h1>Trace properties</h1>
                    <ol style="height: 9em; list-style: none;">
                        <li style="display: flex; flex-direction: column;">
                            <span>A (Boolean) <dfn>specification</dfn>,
                            $\varphi$, is a set of traces.</span>
                            <img class="bigcartoon" src="imgs/trace_prop2.svg"/>
                        </li>
                        <li class="fragment">
                            We say $\xi$ <dfn>satisfies</dfn> $\varphi$,
                            if $\xi \in \varphi$.
                        </li>
                    </ol>
                </section>
                <section>
                    <h1>Trace properties derived from Formal Logic, Automata, etc</h1>
                    <img style="height: 9em" src="imgs/formal_encoding.svg"/>
                    <p class="fragment">Will call a collection of trace properties a concept class.
                    </p>
                    <img class="fragment" style="height: 9em" src="imgs/concept_class.svg"/>
                </section> 


                <!-- ============= Details of specification ================= -->

                <section data-auto-animate class="requirements-overview">
                    <h1>No a-priori order on traces</h1>

                    <div>
                      <img style="height: 10em" src="imgs/compare_1.svg"/>
                    </div>

                    <h1 data-id="1" class="fragment">Agent model induces ordering.</h1>

                    <ol style="height: max-content;">
                      <li class="fragment">Need to know what moves are "risky".</li>
                      <li class="fragment">Need to know agent's objective and competency.</li>
                    </ol>

                </section>

                <!-- ================== Introduce Demonstrations ======================= -->
                <!-- LFD - NeurIPS 2018 -->
                <section data-auto-animate class="lfd1">
                    <h1 data-id="1">Agent model induces ordering</h1>
                    <div>
                        <ul>
                            <li class="fragment" data-id="1">
                                A <dfn>demonstration</dfn> of a task
                                $\varphi$ is an unlabeled example where </br>
                                the agent <strong>tries</strong> to satisfy $\varphi$.

                                <div class="fragment"><img style="height: 8em;" src="imgs/enter_lava.svg"></div>    
                            </li>
                            <li data-id="2" class="fragment">
                                Agency is key. Need a notion of <strong>action</strong>.
                            </li>
                            <li class="fragment">
                                Success probabilities induce an ordering.
                            </li>
                        </ul>
                        <div data-id="3" class="fragment"><img style="height: 5em;" src="imgs/enter_lava2.svg"></div>    
                    </div>
                </section>

                <section class="recipe"
                         data-background-image="imgs/recipe.jpg" >
                    <img style="height: 25em;" src="imgs/inference_recipe.svg"/>
               </section>

                <section class="recipe"
                         data-background-image="imgs/recipe.jpg" >
                    <img style="height: 25em;" src="imgs/inference_recipe_1_2.svg"/>
               </section>


                <section class="irl">
                    <h1>Frame as Inverse Reinforcement Learning</h1>
                    <figure class="fragment">
                        <img style="height: 5em;" src="imgs/mdp.svg"/>
                    </figure>
                    <div class="fragment">
                        \[
                        \max_{\pi} \Big(\mathbb{E}_{s_{1:\tau}}\big(\sum_{i=1}^\tau r(s_i)~|~\pi\big)\Big)
                        \]
                    </div>
                    <div class="fragment">
                        where \[\pi(a~|~s) = \Pr(a~|~s)\]
                    </div>
                    <p style="width: 30em; text-align: left;" class=fragment>
                        Given a series of demonstrations, what reward, $r(s)$, best explains
                        the behavior? <cite style="font-size: 0.8em; opacity: 0.7">(Abbeel and Ng 2004)</cite>
                    </p>
                </section>

                <section class="irl">
                    <h1>No unique explanatory reward!</h1>
                    <div>
                        \[
                        \max_{\pi} \Big(\mathbb{E}_{s_{1:\tau}}\big(\sum_{i=1}^\tau r(s_i)~|~\pi\big)\Big)
                        \]
                    </div>
 
                   <div style="flex-direction: column; border: 1px solid #ffffff73; padding: 1em;" class="fragment">
                    <h2>
                        Maximize Causal Entropy
                    </h2>
 
                        <div data-id="3">
                        \[
                            H(A_{1:\tau}~||~S_{1:\tau}) = \sum_{t=1}^T H\Big(A_{t} \mid S_{1:t}\Big)
                        \]
                        </div>
                        <p>subject to feature statistics.</p>
                        <cite style="font-size: 0.8em; opacity: 0.7">(Ziebart, et al. 2010)</cite>
                    </div>

                </section>
                <section class="irl">
                        <h1>
                          Focus on reward matching 
                        </h1>


                    <div style="opacity: 0.2">
                        \[
                        \max_{\pi} \Big(\mathbb{E}_{s_{1:\tau}}\big(\sum_{i=1}^\tau r(s_i)~|~\pi\big)\Big)
                        \]
                    </div>
                   <div style="flex-direction: column; border: 1px solid #ffffff73; padding: 1em;">
                       <h2 style="opacity: 0.2">
                           Maximize Causal Entropy
                       </h2>
 
                        <div data-id="3" style="opacity: 0.8;">
                        \[
                            H(A_{1:\tau}~||~S_{1:\tau}) = \sum_{t=1}^T H\Big(A_{t} \mid S_{1:t}\Big)
                        \]
                        </div>
                        <p>subject to $E[r]$</p>
                    </div>

                </section>

                <section data-auto-animate class="reduction">
                  <h1 style="width: 15em;">
                    What should the reward be?
                  </h1>

                  <div class="fragment">
                    <img style="height: 8em; margin: 0;" src="imgs/compare_1.svg"/>
                  </div>

                  <h2 style="width: 15em;" class="fragment">
                    <strong>Proposal:</strong> Use indicator.
                  </h2>
                  <div class="fragment" style="font-size: 1.3em" data-id="indicator">
                    \[
                    r(\xi) \triangleq
                    \begin{cases}
                    1 & \text{if } \xi \in \varphi\\
                    0 & \text{otherwise}
                    \end{cases}
                    \]
                  </div>
                  <p class="fragment">\[E[r] = \Pr(\xi \in \varphi)\]</p>
                </section>

                <section data-auto-animate class="reduction">
                  <h1>
                    States are now traces
                  </h1>
                  <div data-id="indicator">
                    \[
                    \scriptsize

                    r(\xi) \triangleq
                    \begin{cases}
                    1 & \text{if } \xi \in \varphi\\
                    0 & \text{otherwise}
                    \end{cases}
                    \]
                  </div>
                 <div class="fragment">
                    <img style="height: 12em;" src="imgs/enter_lava_short.svg"/>
                  </div>

                </section>

                <section class="reduction">
                  <h1>
                      States are now traces
                  </h1>
                  <div data-id="indicator">
                    \[
                    \scriptsize

                    r(\xi) \triangleq
                    \begin{cases}
                    1 & \text{if } \xi \in \varphi\\
                    0 & \text{otherwise}
                    \end{cases}
                    \]
                  </div>
                  <div>
                    <img style="height: 12em;" src="imgs/enter_lava_mdp.svg"/>
                  </div>
                  <p class="fragment">
                    Suppose \(\varphi\) is over traces of length 2.
                  </p>
                </section>

                <section data-auto-animate class="reduction">
                  <h1>
                      States are now traces
                  </h1>


                  <div data-id="indicator">
                    \[
                    \scriptsize

                    r(\xi) \triangleq
                    \begin{cases}
                    1 & \text{if } \xi \in \varphi\\
                    0 & \text{otherwise}
                    \end{cases}
                    \]
                  </div>
                  <div>
                    <img style="height: 15em;" src="imgs/enter_lavat_tree.svg"/>
                  </div>
                  <p >
                    Suppose \(\varphi\) is over traces of length 2.
                  </p>
                </section>

                <section data-auto-animate class="reduction">
                  <h1>Maximum Causal Entropy Policy</h1>
                    <div style="flex-direction: column; margin: 1em; padding: 2em:">
                        <div data-id="6">
                            \begin{equation}
                            \log\big(\pi_{\mathbf{\lambda}}(a~|~s_{1:t})\big) = Q_{\mathbf{\lambda}}(s_{1:t}, a) - V_{\mathbf{\lambda}}(s_{1:t})
                            \end{equation}
                        </div>
                        <span class="fragment" data-id="9">where </span>
                        <div class="fragment" data-id="5">
                          \[
                          V_{\mathbf{\lambda}}(s_{1:t}) \triangleq \begin{cases}
                             \ln \sum_{a} e^{Q_{\mathbf{\lambda}}(s_{1:t}, a)} & \text{if } t \neq \tau,\\
                            \lambda\cdot [s_{1:\tau} \in \varphi] & \text{otherwise}.
                          \end{cases}
                          \]
                        </div>
                        <div class="fragment" data-id="10">
                          \[
                            Q_{\mathbf{\lambda}}(s_{1:t}, a) \triangleq \mathbb{E}_{s_{1:t+1}}\left[ V_{\mathbf{\lambda}}(s_{t+1})~|~s_{1:t}, a\right]
                          \]
                        </div>
                    </div>
                    <p class="fragment">Find $\lambda$ to match $p^*$.</p>
                </section>


                <section data-auto-animate class="reduction">
                  <h1>Entropy regularized bellman backup</h1>
                    <div style="flex-direction: column; margin: 1em; padding: 2em:">
                        <div style="opacity: 0.3" data-id="6">
                            \begin{equation}
                            \log\big(\pi_{\mathbf{\lambda}}(a~|~s_{1:t})\big) = Q_{\mathbf{\lambda}}(s_{1:t}, a) - V_{\mathbf{\lambda}}(s_{1:t})
                            \end{equation}
                        </div>
                        <span style="opacity: 0.3" data-id="9">where </span>
                        <div data-id="5">
                          \[
                          V_{\mathbf{\lambda}}(s_{1:t}) \triangleq \begin{cases}
                             \ln \sum_{a} e^{Q_{\mathbf{\lambda}}(s_{1:t}, a)} & \text{if } t \neq \tau,\\
                            \lambda\cdot [s_{1:\tau} \in \varphi] & \text{otherwise}.
                          \end{cases}
                          \]
                        </div>
                        <div style="opacity: 0.3" data-id="10">
                          \[
                            Q_{\mathbf{\lambda}}(s_{1:t}, a) \triangleq \mathbb{E}_{s_{1:t+1}}\left[ V_{\mathbf{\lambda}}(s_{t+1})~|~s_{1:t}, a\right]
                          \]
                        </div>
                    </div>
                    <p>max ↦ log sum exp.</p>
                    <p class="fragment">$\mathbb{E}[r(s_{1:t})] \mapsto \mathbb{E}[r(s_{1:t})] + H(a\mid s_{1:t})$ </br>
                        <span style="opacity: 0.6">(Geist et al, ICML '19)</span>
                </p>
                </section>

                <section data-auto-animate class="reduction">
                  <h1>Entropy regularized bellman backup</h1>
                    <div style="flex-direction: column; margin: 1em; padding: 2em:">
                        <div style="opacity: 0.3" data-id="6">
                            \begin{equation}
                            \log\big(\pi_{\mathbf{\lambda}}(a~|~s_{1:t})\big) = Q_{\mathbf{\lambda}}(s_{1:t}, a) - V_{\mathbf{\lambda}}(s_{1:t})
                            \end{equation}
                        </div>
                        <span style="opacity: 0.3"  data-id="9">where </span>
                        <div  data-id="5">
                          \[
                          V_{\mathbf{\lambda}}(s_{1:t}) \triangleq \begin{cases}
                             \text{smax}_{a} Q(s_{1:t}, a) & \text{if } t \neq \tau,\\
                            \lambda\cdot [s_{1:\tau} \in \varphi] & \text{otherwise}.
                          \end{cases}
                          \]
                        </div>
                        <div style="opacity: 0.3"  data-id="10">
                          \[
                            Q_{\mathbf{\lambda}}(s_{1:t}, a) \triangleq \mathbb{E}_{s_{1:t+1}}\left[ V_{\mathbf{\lambda}}(s_{t+1})~|~s_{1:t}, a\right]
                          \]
                        </div>
                    </div>
                    <p>max ↦ smooth max (smax).</p>
                </section>


                <section data-auto-animate class="reduction">
                  <h1>Soft Bellman backup</h1>

                    <div style="flex-direction: column; margin: 1em;" 
                         class="boxed small-math">
                        <div data-id="12">
                          \[
                          V_{\mathbf{\lambda}}(s_{1:t}) \triangleq \begin{cases}
                            \text{smax}_{a}Q_\lambda(s_{1:t}, a) & \text{if } t \neq \tau,\\
                            \lambda\cdot 1[s_{1:\tau} \in \varphi] & \text{otherwise}.
                          \end{cases}
                          \]
                        </div>
                        <div data-id="10">
                          \[
                            Q_{\mathbf{\lambda}}(s_{1:t}, a) \triangleq \mathbb{E}_{s_{1:t+1}}\left[ V_{\mathbf{\lambda}}(s_{t+1})~|~s_{1:t}, a\right]
                          \]
                        </div>
                    </div>
                    <div>
                      <img style="height: 13em;" src="imgs/enter_lavat_tree.svg"/>
                    </div>
                </section>

                <section class="reduction">
                    <h1>Find $\lambda$ to match $p^*$.</h1>
                    <div style="flex-direction: column; margin: 1em;" 
                         class="boxed small-math">
                        <div data-id="12">
                          \[
                          V_{\mathbf{\lambda}}(s_{1:t}) \triangleq \begin{cases}
                            \text{smax}_{a}Q_\lambda(s_{1:t}, a) & \text{if } t \neq \tau,\\
                            \lambda\cdot 1[s_{1:\tau} \in \varphi] & \text{otherwise}.
                          \end{cases}
                          \]
                        </div>
                        <div data-id="10">
                          \[
                            Q_{\mathbf{\lambda}}(s_{1:t}, a) \triangleq \mathbb{E}_{s_{1:t+1}}\left[ V_{\mathbf{\lambda}}(s_{t+1})~|~s_{1:t}, a \right]
                          \]
                        </div>
                    </div>
                    <div>
                      <img style="height: 13em;" src="imgs/enter_lava_cgraph.svg"/>
                    </div>
                </section>

                <section data-auto-animate class="reduction">
                    <h1>Satisfaction probability grows monotonically in \(\lambda\).</h1>
                    <div>
                      <img style="height: 13em;" src="imgs/enter_lava_cgraph.svg"/>
                    </div>

                    <p style="width: 33em;">
                    </p>
                    <p style="width: 33em;" class="fragment">Can binary search for \(\lambda\) such that satisfaction probability matches data.</p>
                </section>


                <section data-auto-animate class="reduction">
                  <h1>Naïve computation quickly intractable</h1>

                  <div>
                    <img style="height: 15em;" src="imgs/enter_lavat_tree.svg"/>
                  </div>
                </section>

                <section data-auto-animate class="reduction">
                  <h1 style="opacity: 0.3">Naïve computation quickly intractable</h1>

                  <div style="opacity: 0.3">
                    <img style="height: 15em;" src="imgs/enter_lavat_tree.svg"/>
                  </div>
                  <p>Can do better if you include relevant memory...</p>
                  <p class="fragment">
                      $O(\text{horizon}\cdot|A \times S \times S_\varphi|)$ via dynamic programming...<span class="fragment">but can we do better?</span>
                  </p>
                </section>



               <section>
                    <h1>Consider running example</h1>
                    <img src="imgs/example_domain_3_2.svg"/>
                </section>

                <section class="fancyp">
                    <h1>Focus on choices along demonstration</h1>
                    <figure data-id="1">
                        <img style="height: 7em; margin-top: 2em;" src="imgs/single_demo2.svg"/>
                    </figure>
                </section>

                <section class="fancyp">
                    <h1>Many ways to deviate from demonstration</h1>
                    <figure data-id="1">
                        <img style="height: 7em;" src="imgs/single_demo2.5.svg"/>
                    </figure>
                    <p class="fragment">Each deviation's subtree <strong>summarized</strong> by $V_\lambda, Q_\lambda$.</p>
                </section>

                <section class="fancyp">
                    <h1>Reframe as conforming or deviating</h1>
                    <figure data-id="1">
                        <img style="height: 7em;" src="imgs/single_demo2.5.svg"/>
                    </figure>
                    <p>$\mathbb{E}$ and $\text{smax}$ are <strong>associative</strong></p>
                    <div class="fragment">
                      \[
                        \begin{split}
                          \text{smax}(x, y, z) &= \ln(e^x + e^y + e^z)\\
                                        &= \ln(e^x + e^{\ln(e^y + e^z)})\\

                                        &= \text{smax}(x, \text{smax}(y, z))
                        \end{split}
                      \]
                    </div>
                    <p class="fragment">
                        So we can summarize value of "pivoting" at a given node.
                    </p>
                </section>

                <section class="fancyp" data-auto-animate>
                    <h1>Two choices along a demonstration</h1>
                    <figure data-id="1">
                        <img style="height: 6em;" src="imgs/single_demo3.svg"/>
                    </figure>
                    <figure data-id="2" class="fragment" style="border: solid; margin: 1em;">
                        <img style="height: 5em;" src="imgs/prob_deviate.svg"/>
                    </figure>
                </section>

                <section class="fancyp" >
                    <h1>
                        Multiply <strong>along</strong>
                        demonstration to get likelihood.
                    </h1>
                    <figure data-id="1">
                        <img style="height: 6em;" src="imgs/single_demo3.svg"/>
                    </figure>
                    <figure data-id="2" style="border: solid; margin: 1em;">
                        <img style="height: 5em;" src="imgs/demo_likelihood.svg"/>
                    </figure>
               </section>


                <section class="fancyp" data-auto-animate>
                    <h1>Focus on choices along demonstration</h1>
                    <figure data-id="1">
                        <img style="height: 6em;" src="imgs/single_demo3.svg"/>
                    </figure>
                    <figure data-id="2" style="border: solid; margin: 1em;">
                        <img style="height: 5em;" src="imgs/prob_deviate.svg"/>
                    </figure>
                </section>

                <section>
                    <h1>How to compute action values</h1>
                    <figure data-id="2" style="border: solid; margin: 1em;">
                        <img style="height: 5em;" src="imgs/prob_deviate.svg"/>
                    </figure>
 
                    <ol style="font-size: 1.1em">
                        <li style="margin-top: 0.3em" class="fragment">Dynamic Programming</li>
                        <li style="margin-top: 0.3em" class="fragment">Dynamic Programming on compressed structure</li>
                        <li style="margin-top: 0.3em" class="fragment">Monte Carlo Tree Search <span style="font-size: 0.8em; opacity: 0.8">(e.g., Smooth Cruiser [1])</span></li>
                        <li style="margin-top: 0.3em" class="fragment">Function Approximation <span style="font-size: 0.8em; opacity: 0.8">(e.g., Soft Actor Critic [2])</span></li>
                    </ol>
                    <footer style="opacity: 0.7; font-size: 0.6em; margin-top: 8em;">
                        <cite>[1] Grill, et al. "Planning in entropy-regularized Markov decision processes and games." NeurIPs`19.</cite>
                                </br>
                        <cite>
                            [2] Haarnoja, et al. "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor."  PMLR, `18.
                        </cite>
                    </footer>
                </section>

                <section>
                    <h1>Efficient PAC estimation</h1>
                    <figure data-id="2" style="border: solid; margin: 1em; opacity: 0.3">
                        <img style="height: 5em;" src="imgs/prob_deviate.svg"/>
                    </figure>
 
                    <ol style="font-size: 1.1em">
                        <li style="margin-top: 0.3em; opacity: 0.3">Dynamic Programming</li>
                        <li style="margin-top: 0.3em; opacity: 0.3">Dynamic Programming on compressed structure</li>
                        <li style="margin-top: 0.3em;">Monte Carlo Tree Search <span style="font-size: 0.8em; opacity: 0.8">(e.g., Smooth Cruiser [1])</span></li>
                        <li style="margin-top: 0.3em; opacity: 0.3">Function Approximation <span style="font-size: 0.8em; opacity: 0.8">(e.g., Soft Actor Critic [2])</span></li>
                    </ol>
                    <footer style="opacity: 0.7; font-size: 0.6em; margin-top: 8em;">
                        <cite>[1] Grill, et al. "Planning in entropy-regularized Markov decision processes and games." NeurIPs`19.</cite>
                                </br>
                        <cite>
                            [2] Haarnoja, et al. "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor."  PMLR, `18.
                        </cite>
                    </footer>
                </section>

                <section>
                    <h1>Good in practice. Mileage may vary</h1>
                    <figure data-id="2" style="border: solid; margin: 1em; opacity: 0.3">
                        <img style="height: 5em;" src="imgs/prob_deviate.svg"/>
                    </figure>
 
                    <ol style="font-size: 1.1em">
                        <li style="margin-top: 0.3em; opacity: 0.3">Dynamic Programming</li>
                        <li style="margin-top: 0.3em; opacity: 0.3">Dynamic Programming on compressed structure</li>
                        <li style="margin-top: 0.3em; opacity: 0.3">Monte Carlo Tree Search <span style="font-size: 0.8em; opacity: 0.8">(e.g., Smooth Cruiser [1])</span></li>
                        <li style="margin-top: 0.3em;">Function Approximation <span style="font-size: 0.8em; opacity: 0.8">(e.g., Soft Actor Critic [2])</span></li>
                    </ol>
                    <footer style="opacity: 0.7; font-size: 0.6em; margin-top: 8em;">
                        <cite>[1] Grill, et al. "Planning in entropy-regularized Markov decision processes and games." NeurIPs`19.</cite>
                                </br>
                        <cite>
                            [2] Haarnoja, et al. "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor."  PMLR, `18.
                        </cite>
                    </footer>
                </section>

                <section>
                    <h1>This talk will focus on speeding up *exact* calculation</h1>
                    <figure data-id="2" style="border: solid; margin: 1em; opacity: 0.3">
                        <img style="height: 5em;" src="imgs/prob_deviate.svg"/>
                    </figure>
 
                    <ol style="font-size: 1.1em">
                        <li style="margin-top: 0.3em; opacity: 0.3">Dynamic Programming</li>
                        <li style="margin-top: 0.3em">Dynamic Programming on compressed structure</li>
                        <li style="margin-top: 0.3em; opacity: 0.3">Monte Carlo Tree Search <span style="font-size: 0.8em; opacity: 0.8">(e.g., Smooth Cruiser [1])</span></li>
                        <li style="margin-top: 0.3em; opacity: 0.3">Function Approximation <span style="font-size: 0.8em; opacity: 0.8">(e.g., Soft Actor Critic [2])</span></li>
                    </ol>
                    <footer style="opacity: 0.7; font-size: 0.6em; margin-top: 8em;">
                        <cite>[1] Grill, et al. "Planning in entropy-regularized Markov decision processes and games." NeurIPs`19.</cite>
                                </br>
                        <cite>
                            [2] Haarnoja, et al. "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor."  PMLR, `18.
                        </cite>
                    </footer>
                </section>

                <section>
                    <h1>Take as blackbox for now</h1>
                    <figure data-id="2" style="border: solid; margin: 1em; ">
                        <img style="height: 5em;" src="imgs/prob_deviate.svg"/>
                    </figure>
 
                    <ol style="font-size: 1.1em">
                        <li style="margin-top: 0.3em; opacity: 0.3">Dynamic Programming</li>
                        <li style="margin-top: 0.3em; opacity: 0.3">Dynamic Programming on compressed structure</li>
                        <li style="margin-top: 0.3em; opacity: 0.3">Monte Carlo Tree Search <span style="font-size: 0.8em; opacity: 0.8">(e.g., Smooth Cruiser [1])</span></li>
                        <li style="margin-top: 0.3em; opacity: 0.3">Function Approximation <span style="font-size: 0.8em; opacity: 0.8">(e.g., Soft Actor Critic [2])</span></li>
                    </ol>
                    <footer style="opacity: 0.7; font-size: 0.6em; margin-top: 8em;">
                        <cite>[1] Grill, et al. "Planning in entropy-regularized Markov decision processes and games." NeurIPs`19.</cite>
                                </br>
                        <cite>
                            [2] Haarnoja, et al. "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor."  PMLR, `18.
                        </cite>
                    </footer>
                </section>

                <section data-auto-animate class="structure-of-talk">
                  <h1>Structure of the talk</h1>
                  <div style="opacity: 0.5">
                    <h2 style="text-align: center" data-id="0">
                      Specification motivated agents
                    </h2>
                      <img style="height: 5em;" src="imgs/episodic_learning2.svg"/>
                  </div>
                  <div>
                    <h2 data-id="1" >From demonstrations to specifications </h2>
                  </div>
                  <div style="opacity: 0.1">
                      <h2 data-id="2">Likelihood Calculation in Symbolic MDPs </h2>
                  </div>
                  <div style="opacity: 0.1">
                    <h2 data-id="3"> Conclusion and future work</h2>
                  </div>
                </section>
               <section class="recipe"
                         data-background-image="imgs/recipe.jpg" >
                    <img style="height: 25em;" src="imgs/inference_recipe_2.svg"/>
               </section>

                <section>
                    <h1>Demonstration Informed Specification Search</h1>
                    <img style="height: 23em;" src="imgs/diss_overview3.svg"/>
                </section>

               <section class="fancyp" data-auto-animate>
                    <h1>Goal</h1>
		    <p>Want to find specification that makes the demonstrations unsurprising.</p>
		    <div class="fragment">
			    \[
				h(\varphi) \triangleq  -\sum_{i=1}^n \ln \Pr(\text{demo}_i~|~\varphi, \text{dynamics})
			    \]	
		    </div>

		    <div class="fragment">
			    \[
			    \varphi \sim \text{arg} \min_{\psi\in \Phi} \big \{h(\psi) \big \}
			    \]	
		    </div>
        
               </section>

                <section class="fancyp" data-auto-animate>
                    <h1>View demonstration as a computation tree</h1>
                    <figure data-id="1">
                        <img style="height: 13em; margin-top: 5em;" src="imgs/single_demo4.svg"/>
                    </figure>
                </section>

                <section class="fancyp" >
                    <h1>Environment nodes average</h1>
                    <figure data-id="1">
                        <img style="height: 13em; margin-top: 5em;" src="imgs/single_demo5.svg"/>
                    </figure>
                </section>

                <section class="fancyp" >
                    <h1>Agent nodes softmax</h1>
                    <figure data-id="1">
                        <img style="height: 13em; margin-top: 5em;" src="imgs/single_demo6.svg"/>
                    </figure>
                </section>

                <section class="fancyp">
                    <h1> Surprise <strong>factors</strong> through a function over pivot values. </h1>
                    <figure data-id="2">
                        <img style="height: 13em;" src="imgs/single_demo7.svg"/>
                    </figure>

                    <div class="fragment">
                        \[
                           \widehat{h} : \mathbb{R}^{d} \to [0, 1]
                        \]
                    </div>
                    <div class="fragment">
                        \[
                           h(\varphi) = \widehat{h}(\vec{V}_\varphi)
                        \]
                    </div>
               </section>

                <section class="fancyp" >
                    <h1>How does changing the specification change the pivot value?</h1>
                    <figure style="margin-top: 2em" >
                        <img style="height: 13em;" src="imgs/discrete_image.svg"/>
                    </figure>
                </section>

                <section class="fancyp" data-auto-animate>
                    <h1>Each pivot's subtree <strong>summarized</strong> by V</h1>
                    <figure data-id="3">
                        <img style="height: 17em;" src="imgs/single_demo8.svg"/>
                    </figure>
                </section>

                <section class="fancyp" >
                    <h1 style="width: 27em;">Each <strong>path</strong> given binary label by specification</h1>
                    <figure data-id="3">
                        <img style="height: 17em;" src="imgs/single_demo9.svg"/>
                    </figure>
                </section>

                <section class="fancyp" >
                    <h1>Flipping value <strong>monotonically</strong> changes subtree value</h1>
                    <figure data-id="3">
                        <img style="height: 17em;" src="imgs/single_demo10.svg"/>
                    </figure>

                    <div style="fragment">
                        $V_3 < V_3'$
                    </div>

                    <p style="width: 30em;" class="fragment">Can sample from <strong>$\pi$</strong> to generate high weight paths.</p>
               </section>
                <section class="fancyp" >
                    <h1>Evidence that path is mis-labeled by candidate $\varphi$</h1>
                   <figure style="margin-top: 0em" >
                        <img style="height: 5em;" src="imgs/discrete_image.svg"/>
                    </figure>
                    <figure data-id="3">
                        <img style="height: 6em;" src="imgs/single_demo10.svg"/>
                    </figure>
                    <ol>
                        <li class="fragment">$|\nabla \widehat{h}|$ determines weight of evidence.</li>
                        <li class="fragment">Old label given by $\nabla_i \widehat{h} > 0$.</li>
                        <li class="fragment">New label given by $\nabla_i \widehat{h} < 0$.</li>
                    </ol>
 
               </section>

                <section>
                    <h1>Surprise Guided Sampler</h1>
                    <img style="height: 23em;" src="imgs/sggs.svg"/>
                </section>

               <section class="fancyp" >
                    <h1>Can be seen as walk through labeled example space</h1>
                    <img style="height: 9em; opacity: 0.2" src="imgs/single_demo11.svg"/>
                    <img class="fragment" style="height: 12em;" src="imgs/diss_1.svg"/>
               </section>

                <section class="fancyp" >
                    <h1>Fix algorithm mapping examples to a concept</h1>
                    <img style="height: 9em; opacity: 0.2" src="imgs/single_demo11.svg"/>
                    <img style="height: 12em;" src="imgs/diss_3.svg"/>
               </section>

                <section class="fancyp" >
                    <h1>Does not need to be one-to-one</h1>
                    <img style="height: 9em; opacity: 0.2" src="imgs/single_demo11.svg"/>
                    <img style="height: 12em;" src="imgs/diss_4.svg"/>
               </section>

                <section>
                    <h1>Demonstration Informed Specification Search</h1>
                    <img style="height: 23em;" src="imgs/diss_overview3.svg"/>
                </section>



                <section>
                    <h1>Illustrate on our running example</h1>

                   <img src="imgs/example_domain_6_1.svg"/>
                </section>

                <section>
                    <h1>Find minimal DFA given constraints and demonstration</h1>

                   <img src="imgs/example_domain_6_1.svg"/>
                </section>

                <section>
                    <h1>Start with no labeled examples</h1>

                   <img src="imgs/example_domain_6_2.svg"/>
                </section>

                <section>
                    <h1>Synthesize minimal DFA</h1>

                   <img src="imgs/example_domain_6_3.svg"/>
                </section>

                <section>
                    <h1>Initially "trivial"</h1>

                   <img src="imgs/example_domain_6_4.svg"/>
                </section>

                <section>
                    <h1>Calculate gradient using p=0.8</h1>

                   <img src="imgs/example_domain_6_3_2.svg"/>
                </section>
                 <section>
                    <h1>Pivoting at 9 most likely, but... can't relabel<h1>

                   <img src="imgs/example_domain_6_3_3.svg"/>
                </section>
                 <section>
                    <h1>Can pivot at 3</h1>

                   <img src="imgs/example_domain_6_3_4.svg"/>
                </section>

                <section>
                    <h1>Add to negative example set to adjust V</h1>

                   <img src="imgs/example_domain_6_6.svg"/>
                </section>
                 <section>
                    <h1>Synthesize minimal DFA</h1>

                   <img src="imgs/example_domain_6_6_2.svg"/>
                </section>
                 <section>
                    <h1>Calculate gradient using p=0.8</h1>
                   <img src="imgs/example_domain_6_6_3.svg"/>
                </section>
                 <section>
                    <h1>Pivoting at 9 most likely, and can sample</h1>

                   <img src="imgs/example_domain_6_6_4.svg"/>
                </section>

                 <section>
                    <h1>Mark demonstration as positive example</h1>

                   <img src="imgs/example_domain_6_7.svg"/>
                </section>

                <section>
                    <h1>Don't recharge while wet</h1>

                   <img src="imgs/example_domain_6_7_2.svg"/>
                </section>
                <section>
                    <h1>Lifted in simulated annealing using example buffer</h1>
                    <img style="height: 23em;" src="imgs/diss_overview3.svg"/>
                </section>



                <section class="recipe"
                         data-background-image="imgs/recipe.jpg" >
                    <img style="height: 25em;" src="imgs/inference_recipe.svg"/>
               </section>
                <section class="structure-of-talk">
                  <h1>Structure of the talk</h1>
                  <div style="opacity: 0.5">
                    <h2 style="text-align: center" data-id="0">
                      Specification motivated agents
                    </h2>
                      <img style="height: 5em;" src="imgs/episodic_learning2.svg"/>
                  </div>
                  <div style="opacity: 0.5">
                    <h2 data-id="1" >From demonstrations to specifications </h2>
                  </div>
                  <div>
                      <h2 data-id="2">Likelihood Calculation in Symbolic MDPs </h2>
                  </div>

                  <div style="opacity: 0.1">
                    <h2 data-id="3"> Conclusion and future work</h2>
                  </div>
                </section>


                <section data-auto-animate class="reduction">
                  <h1>Backup as computation graph</h1>

                    <div>
                      <img style="height: 13em;" src="imgs/enter_lava_cgraph.svg"/>
                    </div>

                    <p><strong>Problem:</strong> Unrolled tree grows exponentially in horizon!</p>
                </section>


                <section data-auto-animate class="reduction">
                  <h1>Backup as computation graph</h1>

                    <div>
                      <img style="height: 13em;" src="imgs/enter_lava_cgraph.svg"/>
                    </div>


                    <p style="text-align: left; width: 30em;"><strong>Observation 1:</strong> A lot of shared structure in computation graph.</p>
                    <p style="text-align: left; width: 30em;" class="fragment"><strong>Observation 2:</strong> System and environment actions are ordered.</p>
                    

                </section>

                <section data-auto-animate class="random-bit-model">
                  <h1>Circuit model</h1>
                  
                  <p style="width: 25em"> 
                      Represent Markov Decision Process as
                      deterministic transition system with access to
                      $n_c$ (biased) coin flips.
                  </p>
                  <figure class="fragment">
                    <img style="height: 6em;" src="imgs/mdp_circ0.svg">
                  </figure>
                  <div data-id="3" class="fragment boxed">
                    \[
                       \text{Dynamics} : S \times {\{0, 1\}}^{n_a + n_c} \to S
                    \]
                  </div>
                  <p class="fragment">Guaranteed to exist for finite horizon, actions, and transition support.</p>
                  <footer>
                      <cite style="font-size: 0.5em; opacity: 0.5">
                                Vazquez-Chanlatte, Marcell, Markus
                                N. Rabe, and Sanjit A. Seshia. "A
                                Model Counter's Guide to Probabilistic
                                Systems.". `19
                      </cite>
 
                  </footer>
                </section>

                <section data-auto-animate class="random-bit-model">
                  <h1>Unrolling and composing with specification results in a predicate</h1>
                  <figure data-id="1">
                    <img style="height: 7em;" src="imgs/mdp_circ_unrolled.svg">
                  </figure>

                  <div class="fragment boxed" data-id="2">
                    \[
                       \psi : {\{0, 1\}}^{\tau\cdot (n_a + n_c)} \to \{0, 1\}
                    \]
                  </div>

                </section>


                <section data-auto-animate class="reduction">
                  <h1>Backup as computation graph</h1>

                    <div>
                      <img style="height: 13em;" src="imgs/enter_lava_cgraph.svg"/>
                    </div>

                    <p data-id="3"><strong>Idea:</strong> Encode graph as a binary predicate
                      \[
                      \psi: \{0, 1\}^n \to \{0,1\}
                      \]
                      <span>
                      and represent as Reduced Ordered Binary Decision Diagram</br>
                      <cite>(Bryant 1986)</cite>.
                      </span>
                    </p>
                    
                </section>

                <section data-auto-animate class="random-bit-model">
                  <h1>Random Bit Model</h1>
                  <div data-id="2">
                    \[
                       \psi : {\{0, 1\}}^{\tau\cdot (n_a + n_c)} \to \{0, 1\}
                    \]
                  </div>
                  <p style="width: max-content;">
                    <strong>Proposal:</strong> Represent \(\psi\) as Binary Decision Diagram with bits in causal order.
                  </p>
                  <figure class="fragment">
                    <img style="height: 15em;" src="imgs/bitorder.svg"/>
                  </figure>
                </section>

                <section data-auto-animate class="random-bit-model">
                    <h1>
                        Reduced Causally Ordered Binary Decisian Diagram
                    </h1>
                  <figure>
                    <img style="height: 20em; margin:0; padding: 0;" src="imgs/bdd_lava.svg"/>
                  </figure>
                </section>

                <section class="mce-bdds">
                  <h1>How to compute values on causally ordered BDDs?</h1>
                  <figure>
                    <img style="opacity: 0.3; height: 20em; margin:0; padding: 0;" src="imgs/bdd_lava.svg"/>
                  </figure>
 
                   <ol class="fragment">
                      <li>Associativity of <span data-id="3">\(\text{smax}\)</span> and <span data-id="5">\(\mathbb{E}\)</span>.
                      </li>
                      <li>
                        \(\text{smax}(\alpha, \alpha) = \alpha + \ln(2)\)
                      </li>
                      <li >
                        \(\text{E}(\alpha, \alpha) = \alpha\)
                      </li>
                    </ol>
               </section>
                <section class="mce-bdds">
                  <h1>Re-interpret as computation graph</h1>
                 <figure>
                    <img style="height: 20em; margin:0; padding: 0;" src="imgs/bdd_cgraph.svg"/>
                  </figure>
                    <ol>
                      <li>Associativity of <span data-id="3">\(\text{smax}\)</span> and <span data-id="5">\(\mathbb{E}\)</span>.
                      </li>
                      <li>
                        \(\text{smax}(\alpha, \alpha) = \alpha + \ln(2)\)
                      </li>
                      <li >
                        \(\text{E}(\alpha, \alpha) = \alpha\)
                      </li>
                    </ol>
 
                </section>

                <section data-auto-animate class="mce-bdds">
                  <h1>How big can these Causal BDDs be?</h1>
                  <div data-id="1" style="flex-direction: column;">
                    \[
                    |BDD| \leq \overbrace{\underbrace{\tau}_{\text{horizon}} \cdot  \big( \log(|A|) + \text{#coins} \big)}^{\text{# inputs}} \cdot \big( \underbrace{|S / \varphi|\cdot|A|}_{\text{composed automaton}} \cdot 2^{\text{#coins}} \big)
                    \]
                  </div>
                  <p class="fragment" style="width: 34em;"><strong>Linear</strong> in horizon!</p>
                  <p style="width: 34em;" class="fragment"><strong>Note:</strong> Using function composition, can build BDD efficiently.</p>
                  <footer style="margin-top: 7em">
                      <cite style="opacity: 0.5; width: 25em;">
                          Vazquez-Chanlatte, 
                          "Maximum Causal Entropy Specification </br>
                          Inference from Demonstrations",
                          CAV `20
                      </cite>
                  </footer>
                </section>

                <section data-auto-animate class="mce-bdds">
                  <h1>Works for Markov Chains and Stochastic Games too!</h1>
                  <div style="opacity: 0.5" data-id="1" style="flex-direction: column;">
                    \[
                    |BDD| \leq \overbrace{\underbrace{\tau}_{\text{horizon}} \cdot  \big( \log(|A|) + \text{#coins} \big)}^{\text{# inputs}} \cdot \big( \underbrace{|S / \varphi|\cdot|A|}_{\text{composed automaton}} \cdot 2^{\text{#coins}} \big)
                    \]
                  </div>
                  <ol style="width: 25em; font-size: 0.8em; padding: 0.3em;">
                      <li class="fragment">
                          <strong>Markov Chains:</strong> Sebastian Junges, Steven Holtzen, Marcell
                          Vazquez-Chanlatte, Todd Millstein, Guy Van den
                          Broerk, Sanjit A. Seshia. "Model Checking
                          Finite-Horizon Markov Chains with Probabilistic
                          Inference", CAV `21. 
                      </li>
                      <li style="margin-top: 1em" class="fragment">
                          <strong>Stochastic Games:</strong> Marcell Vazquez-Chanlatte, 
                          Sebastian, Daniel J. Fremont, Sanjit
                          A. Seshia. "Entropy Guided Control
                          Improvisation", RSS `21
                      </li>
                  </ol>
               </section>

                <section data-auto-animate class="mce-bdds">
                  <h1>Outperforms Probablistic Model Checker on some benchmarks</h1>
                  <div style="opacity: 0.3" data-id="1" style="flex-direction: column;">
                    \[
                    |BDD| \leq \overbrace{\underbrace{\tau}_{\text{horizon}} \cdot  \big( \log(|A|) + \text{#coins} \big)}^{\text{# inputs}} \cdot \big( \underbrace{|S / \varphi|\cdot|A|}_{\text{composed automaton}} \cdot 2^{\text{#coins}} \big)
                    \]
                  </div>
                  <ol style="width: 25em; font-size: 0.8em; padding: 0.3em;">
                      <li>
                          <strong>Markov Chains:</strong> Junges, Sebastian, Steven Holtzen, Marcell
                          Vazquez-Chanlatte, Todd Millstein, Guy Van den
                          Broerk, Sanjit A. Seshia. "Model Checking
                          Finite-Horizon Markov Chains with Probabilistic
                          Inference", CAV `21. 
                      </li>
                      <li style="margin-top: 1em; opacity: 0.3;" >
                          <strong>Stochastic Games:</strong> Vazquez-Chanlatte, Marcell, Junges,
                          Sebastian, Daniel J. Fremont, Sanjit
                          A. Seshia. "Entropy Guided Control
                          Improvisation", RSS `21
                      </li>
                  </ol>
               </section>
                <section data-auto-animate class="mce-bdds">
                  <h1>Max Causal entropy control under uncertain dynamics</h1>
                  <div style="opacity: 0.5" data-id="1" style="flex-direction: column;">
                    \[
                    |BDD| \leq \overbrace{\underbrace{\tau}_{\text{horizon}} \cdot  \big( \log(|A|) + \text{#coins} \big)}^{\text{# inputs}} \cdot \big( \underbrace{|S / \varphi|\cdot|A|}_{\text{composed automaton}} \cdot 2^{\text{#coins}} \big)
                    \]
                  </div>
                  <ol style="width: 25em; font-size: 0.8em; padding: 0.3em;">
                      <li style="opacity: 0.3">
                          <strong>Markov Chains:</strong> Junges, Sebastian, Steven Holtzen, Marcell
                          Vazquez-Chanlatte, Todd Millstein, Guy Van den
                          Broerk, Sanjit A. Seshia. "Model Checking
                          Finite-Horizon Markov Chains with Probabilistic
                          Inference", CAV `21. 
                      </li>
                      <li style="margin-top: 1em">
                          <strong>Stochastic Games:</strong> Vazquez-Chanlatte, Marcell, Junges,
                          Sebastian, Daniel J. Fremont, Sanjit
                          A. Seshia. "Entropy Guided Control
                          Improvisation", RSS `21
                      </li>
                  </ol>
               </section>

               <section>
                   <h1>Example: Drone test harness</h1>
                    <img style="height: 22em;" src="imgs/experiment_0.svg">
                </section>
                 <section>
                     <h1>Want to certify green delivery drone</h1>
                    <img style="height: 22em;" src="imgs/experiment_1.svg">
                </section>
	        <section>
                    <h1>Will ask the drone to deliver packages</h1>
                    <img style="height: 22em;" src="imgs/experiment_7.svg">
                </section>
	        <section>
                    <h1>Run the drone a few times to get dynamics estimate</h1>
                    <img style="height: 22em;" src="imgs/experiment_8.svg">
                </section>
	
                <section>
                    <h1>Want to test green drone in presence of (certified) blue drone</h1>
                    <img style="height: 22em;" src="imgs/experiment_3.svg">
                </section>

	        <section>
                    <h1>Synthesize maximally random improviser for blue drone</h1>
                    <img style="height: 22em;" src="imgs/experiment_5.svg">
                </section>


               <section>
                    <img  style="height: 25em;" src="imgs/time_vs_bddsize.svg"/>
                </section>
                <section>
                    <img  style="height: 24em;" src="imgs/bdd_size_by_horizon.svg"/>
                </section>
	

                <section data-auto-animate class="structure-of-talk">
                  <h1>Structure of the talk</h1>
                  <div style="opacity: 0.5">
                    <h2 style="text-align: center" data-id="0">
                      Specification motivated agents
                    </h2>
                      <img style="height: 5em;" src="imgs/episodic_learning2.svg"/>
                  </div>
                  <div style="opacity: 0.5">
                    <h2 data-id="1" >From demonstrations to specifications </h2>
                  </div>
                  <div style="opacity: 0.5">
                      <h2 data-id="2">Likelihood Calculation in Symbolic MDPs </h2>
                  </div>
                  <div>
                    <h2 data-id="3"> Conclusion and future work</h2>
                  </div>
                </section>

               <section>
                   <h1>In this talk</h1>
                    <figure data-id="1" style="opacity: 0.3">
                        <img data-id="2" style="height: 5em" src='imgs/episodic_learning_still.svg'>
                    </figure>
 
                    <ol style="font-size: 1em; margin-top: 1em;">
                        <li>Max (causal) entropy forecasting of specification driven agents in MDPs and Stochastic Games
                            <br>
                            <cite style="opacity: 0.7; font-size: 0.85em; color: white">
                                "Learning Task Specifications from
                                Demonstrations." NeurIPS `18. 
                            </cite>
                            <br>
                            <cite style="opacity: 0.7; font-size: 0.85em; color: #70ff70">
                                "Maximum Causal Entropy
                                Specification Inference from
                                Demonstrations." CAV `20
                            </cite>
                             <br>
                            <cite style="opacity: 0.7; font-size: 0.85em; color: cyan">
                                 "Entropy Guided Control
                                Improvisation", RSS `21
 
                            </cite>
                        </li>
                        <li class="fragment" style="margin-top: 1em">Value calculuation on symbolic Marko Chains, MDPs and Stochastic Games
                            <br>
                            <cite style="opacity: 0.7; font-size: 0.85em; color: yellow">
                                "A
                                Model Counter's Guide to Probabilistic
                                Systems.". (preprint)
                            </cite>

 
                            <br>
                            <cite style="opacity: 0.7; font-size: 0.85em; color: orange">

                                "Model Checking Finite-Horizon Markov
                                Chains with Probabilistic Inference",
                                CAV `21
                            </cite>

                            <br> 
                            <cite style="opacity: 0.7; font-size: 0.85em; color: #70ff70">
                                "Maximum Causal Entropy
                                Specification Inference from
                                Demonstrations." CAV `20
                            </cite>
                             <br>
                            <cite style="opacity: 0.7; font-size: 0.85em; color: cyan">
                                 "Entropy Guided Control
                                Improvisation", RSS `21
                            </cite>
                        </li>
                        <li style="margin-top: 1em" class="fragment">
                            Searching for likely specifications given demonstrations
                            <br>
                            <cite style="opacity: 0.7; font-size: 0.85em; color: white">
                                "Learning Task Specifications from
                                Demonstrations." NeurIPS `18. 
                            </cite>
                            <br> 

                            <cite style="opacity: 0.7; font-size: 0.85em; color: #e5acff">
                                "Demonstration Informed Specification Search." In progress.
                            </cite>
                        </li>
                    </ol> 
 
               </section>


               <section>
                   <h1>By no means solved</h1>
                    <img data-id="3"
                         style="height: 22em;"
                         src="imgs/intent_inference_apps.svg"/>
               </section>
               <section>
                   <h1>Clear path to scaling up</h1>
                    <figure data-id="3">
                        <img style="height: 10em;" src="imgs/single_demo11.svg"/>
                    </figure>

                    <ol style="font-size: 1.3em; margin-top: 1em;">
                        <li class="fragment">Need a way to estimate values.</li>
                        <li class="fragment">Need a way to sample likely paths from policy.</li>
                    </ol>
               </section>
                <section>
                    <h1>Plays nicely with approximate methods</h1>
                    <figure data-id="2" style="border: solid; margin: 1em; opacity: 0.3">
                        <img style="height: 5em;" src="imgs/prob_deviate.svg"/>
                    </figure>
 
                    <ol style="font-size: 1.1em">
                        <li style="margin-top: 0.3em; opacity: 0.3;" >Dynamic Programming</li>
                        <li style="margin-top: 0.3em; opacity: 0.3;" >Dynamic Programming on compressed structure</li>
                        <li style="margin-top: 0.3em" >Monte Carlo Tree Search <span style="font-size: 0.8em; opacity: 0.8">(e.g., Smooth Cruiser [1])</span></li>
                        <li style="margin-top: 0.3em" >Function Approximation <span style="font-size: 0.8em; opacity: 0.8">(e.g., Soft Actor Critic [2])</span></li>
                    </ol>
                    <footer style="opacity: 0.7; font-size: 0.6em; margin-top: 8em;">
                        <cite>[1] Grill, et al. "Planning in entropy-regularized Markov decision processes and games." NeurIPs`19.</cite>
                                </br>
                        <cite>
                            [2] Haarnoja, et al. "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor."  PMLR, `18.
                        </cite>
                    </footer>
                </section>
                <section>
                    <h1>Natural path for combining symbolic and MCTS methods</h1>
                    <figure data-id="2" style="border: solid; margin: 1em; opacity: 0.3">
                        <img style="height: 5em;" src="imgs/prob_deviate.svg"/>
                    </figure>
 
                    <ol style="font-size: 1.1em">
                        <li style="margin-top: 0.3em; opacity: 0.3;" >Dynamic Programming</li>
                        <li style="margin-top: 0.3em;" >Dynamic Programming on compressed structure</li>
                        <li style="margin-top: 0.3em;" >Monte Carlo Tree Search <span style="font-size: 0.8em; opacity: 0.8">(e.g., Smooth Cruiser [1])</span></li>
                        <li style="margin-top: 0.3em; opacity: 0.3;" >Function Approximation <span style="font-size: 0.8em; opacity: 0.8">(e.g., Soft Actor Critic [2])</span></li>
                    </ol>
                    <footer style="opacity: 0.7; font-size: 0.6em; margin-top: 8em;">
                        <cite>[1] Grill, et al. "Planning in entropy-regularized Markov decision processes and games." NeurIPs`19.</cite>
                                </br>
                        <cite>
                            [2] Haarnoja, et al. "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor."  PMLR, `18.
                        </cite>
                    </footer>
                </section>
               <section>
                   <h1>Multi-agent (inferred) assume guarantee reasoning underexplored</h1>
                   <p style="font-size: 1.3em">\[ A \implies G\]</p>
                   <img style="height: 13em" src="imgs/intent_inference_apps_2.svg"/>
                   <p class="fragment" style="font-size: 0.8em">
                       Maximum causal entropy correlated equillibria
                       seem like an interesting model
                       <br>
                       <cite style="opacity: 0.7; font-size: 0.7em">Ziebart, et al., "Maximum causal entropy correlated equilibria for Markov games." AAAI `10.</cite>
                   </p>
               </section>
		<section>

                    <h3 style="opacity: 0.95">Questions?</h3>

                    <figure style="opacity: 0.7" data-id="1">
                        <img data-id="2" style="height: 10em;" src='imgs/episodic_learning2.svg'>
                    </figure>
 



                    <footer style="margin-top: 8em; font-size: 0.5em; opacity: 0.6" >
                        <h6>A learning biased discussion of the following work</h6>
                        <ul>
                            <li>
                                Marcell Vazquez-Chanlatte, Susmit
                                Jha, Ashish Tiwari, Mark K. Ho, and
                                Sanjit A. Seshia. "Learning Task
                                Specifications from Demonstrations."
                                NeurIPS. `18. 
                            </li>
                            <li>
                                Marcell, and Sanjit
                                A. Seshia. "Maximum Causal Entropy
                                Specification Inference from
                                Demonstrations." CAV `20
                            </li>
                            <li>
                                Marcell Vazquez-Chanlatte, Markus
                                N. Rabe, and Sanjit A. Seshia. "A
                                Model Counter's Guide to Probabilistic
                                Systems.". `19
                            </li>
                            <li>
                                Marcell Vazquez-Chanlatte, Sebastian Junges,
                                Daniel J. Fremont, Sanjit
                                A. Seshia. "Entropy Guided Control
                                Improvisation", RSS `21
                            </li>
                            <li>
                                Sebastian Junges, Steven Holtzen,
                                Marcell Vazquez-Chanlatte, Todd
                                Millstein, Guy Van den Broerk, Sanjit
                                A. Seshia. "Model Checking
                                Finite-Horizon Markov Chains with
                                Probabilistic Inference", CAV `21
                            </li>
                        </ul>
                    </footer>
               </section>

            </div>
	</div>

	<script src="dist/reveal.js"></script>
	<script src="plugin/notes/notes.js"></script>
	<script src="plugin/markdown/markdown.js"></script>
	<script src="plugin/highlight/highlight.js"></script>
        <script src="plugin/math/math.js"></script>
	<script>
	 // More info about initialization & config:
	 // - https://revealjs.com/initialization/
	 // - https://revealjs.com/config/
	 Reveal.initialize({
	     hash: true,
             width: 1920,
             height: 1080,
             slideNumber: 'c',
             progress: true,
             display: 'flex',
             controls: false,
             transition: 'none',
             center: false,
	     // Learn about plugins: https://revealjs.com/plugins/
	     plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath ]
	 });
	</script>
    </body>
</html>
