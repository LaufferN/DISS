{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration Informed Specification Search: Experiment\n",
    "\n",
    "Let's take a look at how the DISS algorithm can search for specifications by leveraging expert demonstrations. \n",
    "We'll focus on learning DFAs in this case, but note that this approach is not confined to any specific concept class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "import funcy as fn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bidict import bidict\n",
    "from IPython.display import Image, display\n",
    "import networkx as nx\n",
    "import pydot\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import dfa\n",
    "from dfa.utils import find_subset_counterexample, find_equiv_counterexample\n",
    "from dfa_identify import find_dfa, find_dfas\n",
    "\n",
    "from diss.product_mc import ProductMC\n",
    "from diss.dfa_concept import DFAConcept\n",
    "from diss.domains.gridworld_naive import GridWorldNaive as World\n",
    "from diss.domains.gridworld_naive import GridWorldState as State\n",
    "from diss import search, LabeledExamples, GradientGuidedSampler, ConceptIdException\n",
    "from pprint import pprint\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm.notebook import trange\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<style>\n",
    "    .jp-OutputArea-child {\n",
    "        display: inline-block;\n",
    "    }\n",
    "</style>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper')\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first visualize our gridworld and a demonstration within the gridworld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML as html_print\n",
    "\n",
    "\n",
    "COLOR_ALIAS = {\n",
    "    'yellow': '#ffff00', 'brown': '#ffb081',\n",
    "    'red': '#ff8b8b', 'blue': '#afafff', 'green' : '#67f7a1'\n",
    "}\n",
    "\n",
    "\n",
    "def tile(color='black'):\n",
    "    color = COLOR_ALIAS.get(color, color)\n",
    "    s = '&nbsp;'*4\n",
    "    return f\"<text style='border: solid 1px;background-color:{color}'>{s}</text>\"\n",
    "\n",
    "\n",
    "def ap_at_state(x, y, world):\n",
    "    \"\"\"Use sensor to create colored tile.\"\"\"\n",
    "    if (x, y) in world.overlay:\n",
    "        color = world.overlay[(x,y)]\n",
    "\n",
    "        if color in COLOR_ALIAS.keys():\n",
    "            return tile(color)\n",
    "    return tile('white')\n",
    "\n",
    "def print_map(world):\n",
    "    \"\"\"Scan the board row by row and print colored tiles.\"\"\"\n",
    "    order = range(1, world.dim + 1)\n",
    "    for y in order:\n",
    "        chars = (ap_at_state(x, y, world) for x in order)\n",
    "        display(html_print('&nbsp;'.join(chars)))\n",
    "        \n",
    "def print_trc(trc, idx=0):\n",
    "    actions, states = trc\n",
    "    obs = (ap_at_state(*pos, in_ascii=True) for pos in states)\n",
    "    display(\n",
    "        html_print(f'trc {idx}:&nbsp;&nbsp;&nbsp;' + ''.join(''.join(x) for x in zip(actions, obs)) + '\\n')\n",
    "    )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw = World(\n",
    "    dim=3,\n",
    "    start=State(x=3, y=1),\n",
    "    overlay={\n",
    "      (1, 1): 'yellow',\n",
    "      (1, 2): 'green',\n",
    "      (1, 3): 'green',\n",
    "      (2, 3): 'red',\n",
    "      (3, 2): 'blue',\n",
    "      (3, 3): 'blue',\n",
    "    }\n",
    ")\n",
    "\n",
    "print()\n",
    "state = gw.start\n",
    "#print(gw.to_string(state))\n",
    "assert gw.player(state) == 'ego'\n",
    "assert len(gw.moves(state)) == 2\n",
    "\n",
    "move_hist = Counter(len(gw.moves(m)) for m in gw.moves(state))\n",
    "assert move_hist == {1: 1, 2: 1}\n",
    "assert all(gw.player(m) == 'env' for m in gw.moves(state))\n",
    "\n",
    "state = State(x=2, y=2)\n",
    "assert gw.player(state) == 'ego'\n",
    "assert len(gw.moves(state)) == 4\n",
    "\n",
    "demos = [[\n",
    "   (State(3, 1), 'ego'),\n",
    "   (State(3, 1, '←'), 'env'),\n",
    "   (State(3, 2), 'ego'),\n",
    "   (State(3, 2, '←'), 'env'),\n",
    "   (State(2, 2), 'ego'),\n",
    "   (State(2, 2, '←'), 'env'),\n",
    "   (State(1, 2), 'ego'),\n",
    "   (State(1, 2, '↑'), 'env'),\n",
    "   (State(1, 1), 'ego'),\n",
    "]]\n",
    "#print(gw.to_string(state))\n",
    "print_map(gw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can define a set of expert demonstrations for this gridworld to guide our specification search procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw = World(\n",
    "    dim=3,\n",
    "    start=State(x=3, y=1),\n",
    "    overlay={\n",
    "      (1, 1): 'yellow',\n",
    "      (1, 2): 'green',\n",
    "      (1, 3): 'green',\n",
    "      (2, 3): 'red',\n",
    "      (3, 2): 'blue',\n",
    "      (3, 3): 'blue',\n",
    "    }\n",
    ")\n",
    "\n",
    "print()\n",
    "state = gw.start\n",
    "assert gw.player(state) == 'ego'\n",
    "assert len(gw.moves(state)) == 2\n",
    "\n",
    "move_hist = Counter(len(gw.moves(m)) for m in gw.moves(state))\n",
    "assert move_hist == {1: 1, 2: 1}\n",
    "assert all(gw.player(m) == 'env' for m in gw.moves(state))\n",
    "\n",
    "state = State(x=2, y=2)\n",
    "assert gw.player(state) == 'ego'\n",
    "assert len(gw.moves(state)) == 4\n",
    "\n",
    "demos = [[\n",
    "   (State(3, 1), 'ego'),\n",
    "   (State(3, 1, '←'), 'env'),\n",
    "   (State(3, 2), 'ego'),\n",
    "   (State(3, 2, '←'), 'env'),\n",
    "   (State(2, 2), 'ego'),\n",
    "   (State(2, 2, '←'), 'env'),\n",
    "   (State(1, 2), 'ego'),\n",
    "   (State(1, 2, '↑'), 'env'),\n",
    "   (State(1, 1), 'ego'),\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with some very simple base examples to warm-start our specification search process. We want to synthesize a spec that's consistent with the observed evidence thus far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fn.memoize(key_func=lambda c, t: c.dfa)\n",
    "def to_chain(c, t):\n",
    "    #print('building chain')\n",
    "    chain = ProductMC.construct(\n",
    "        concept=c, tree=t, dyn=gw, max_depth=9, psat=0.8\n",
    "    )\n",
    "    #print('done building chain')\n",
    "    return chain\n",
    "\n",
    "\n",
    "def sampler_factory(demos):\n",
    "    return GradientGuidedSampler.from_demos(\n",
    "        demos=demos,\n",
    "        to_chain=to_chain,\n",
    "    )\n",
    "\n",
    "base_examples = LabeledExamples(\n",
    "    positive=[\n",
    "        ('yellow',),\n",
    "        ('yellow', 'yellow'),\n",
    "    ],\n",
    "    negative=[\n",
    "        (), ('red',), ('red', 'red'),\n",
    "        ('red', 'yellow'), ('yellow', 'red'),\n",
    "        ('yellow', 'red', 'yellow'),\n",
    "        ('yellow', 'yellow', 'red'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going from the partial spec to a full spec :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_dfa(inputs):\n",
    "    def transition(s, c):\n",
    "        if c == 'red':\n",
    "            return s | 0b01\n",
    "        elif c == 'yellow':\n",
    "            return s | 0b10\n",
    "        return s\n",
    "\n",
    "    return dfa.DFA(\n",
    "        start=0b00,\n",
    "        inputs=inputs,\n",
    "        label=lambda s: s == 0b10,\n",
    "        transition=transition\n",
    "    )\n",
    "\n",
    "def trace(path):\n",
    "    return tuple(x for x in map(gw.sensor, path) if x != 'white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can outline the machinery for the search process itself. We use the solution procedure in the DFA identification algorithm to synthesize a minimal DFA (in both states and non-stuttering edges) that is consistent with the observed examples to this point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fn.memoize(key_func=lambda accepting, rejecting, alphabet, order_by_stutter: hash((accepting, rejecting)))\n",
    "def find_dfas2(accepting, rejecting, alphabet, order_by_stutter):\n",
    "    #print('Identify DFAs')\n",
    "    dfas = find_dfas(accepting, rejecting, alphabet=alphabet, order_by_stutter=order_by_stutter)\n",
    "    dfas = fn.take(10, dfas)\n",
    "    #print('Done')\n",
    "    return dfas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_check_wrapper(dfa_candidate):\n",
    "    partial = partial_dfa(dfa_candidate.inputs)\n",
    "    ce = find_subset_counterexample(dfa_candidate, partial)\n",
    "    return ce is None\n",
    "\n",
    "\n",
    "ALPHABET = frozenset({'red', 'yellow', 'blue', 'green'})\n",
    "\n",
    "\n",
    "@fn.memoize\n",
    "def subset_cegis(data):\n",
    "    global base_examples\n",
    "    #print('Start CEGIS Loop for Subset')\n",
    "\n",
    "    for i in range(20):\n",
    "        mydfa = find_dfa(data.positive, data.negative, order_by_stutter=True) \n",
    "        if mydfa is None:\n",
    "            raise ConceptIdException\n",
    "        partial = partial_dfa(mydfa.inputs)\n",
    "        ce = find_subset_counterexample(mydfa, partial)\n",
    "        if ce is None:\n",
    "            break\n",
    "        base_examples @= LabeledExamples(negative=[ce])\n",
    "        data @= LabeledExamples(negative=[ce])\n",
    "\n",
    "        partial = partial_dfa(mydfa.inputs)\n",
    "        for k, lbl in enumerate(partial.transduce(ce)):\n",
    "            prefix = ce[:k]\n",
    "            if not lbl:\n",
    "                base_examples @= LabeledExamples(negative=[prefix])\n",
    "                data @= LabeledExamples(negative=[prefix])\n",
    "    #print('Done')\n",
    "    return data\n",
    "\n",
    "\n",
    "def to_concept(data, skip_trace=False):\n",
    "    global base_examples\n",
    "    \n",
    "    if not skip_trace:\n",
    "        data = LabeledExamples(\n",
    "            positive = frozenset([trace(x) for x in data.positive]),\n",
    "            negative = frozenset([trace(x) for x in data.negative]),\n",
    "        )\n",
    "    data @= base_examples\n",
    "    data = subset_cegis(data)\n",
    "\n",
    "    #print('Sampling Concept')\n",
    "    concept = DFAConcept.from_examples(data, gw.sensor, subset_check_wrapper, alphabet=ALPHABET, find_dfas=find_dfas2) \n",
    "    #print('Done')\n",
    "    return concept\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diss.dfa_concept import remove_stutter\n",
    "from collections import defaultdict\n",
    "\n",
    "# adapted from the dfa library\n",
    "def get_dot(dfa_):\n",
    "    dfa_dict, init = dfa.dfa2dict(dfa_)\n",
    "    remove_stutter(dfa_dict)\n",
    "    g = pydot.Dot(rankdir=\"LR\")\n",
    "\n",
    "    nodes = {}\n",
    "    for i, (k, (v, _)) in enumerate(dfa_dict.items()):\n",
    "        shape = \"doublecircle\" if v else \"circle\"\n",
    "        nodes[k] = pydot.Node(i+1, label=f\"{k}\", shape=shape)\n",
    "        g.add_node(nodes[k])\n",
    "\n",
    "    edges = defaultdict(list)\n",
    "    for start, (_, transitions) in dfa_dict.items():        \n",
    "        for action, end in transitions.items():\n",
    "            color = COLOR_ALIAS[str(action)]\n",
    "            edges[start, end].append(color)\n",
    "    \n",
    "    init_node = pydot.Node(0, shape=\"point\", label=\"\")\n",
    "    g.add_node(init_node)\n",
    "    g.add_edge(pydot.Edge(init_node, nodes[init]))\n",
    "\n",
    "    for (start, end), colors in edges.items():\n",
    "        for color in colors:\n",
    "            g.add_edge(pydot.Edge(nodes[start], nodes[end], label='⬛', fontcolor=color))\n",
    "            \n",
    "    return g\n",
    "\n",
    "def view_pydot(pdot):\n",
    "    #pdot = nx.drawing.nx_pydot.to_pydot(pdot_graph)\n",
    "    plt = Image(pdot.create_png())\n",
    "    display(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated Annealed + SGGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "example_sampler = sampler_factory(demos)\n",
    "\n",
    "unlabeled = set()\n",
    "dfa_dist = {}\n",
    "n_iters = 5\n",
    "n_sggs_trials = 5\n",
    "t = 0\n",
    "labeled = LabeledExamples()\n",
    "for i in trange(n_iters, desc=\"Number of times to restart ----\"):\n",
    "    prev_energy = float('inf')\n",
    "    for j in trange(n_sggs_trials, desc='SGGS + Simulated Annealing', leave=False):\n",
    "        t += 1\n",
    "        # 1. Set temperature.\n",
    "        temp = 10*(1 - t / (n_iters*n_sggs_trials)) + 0.01\n",
    "        \n",
    "        # 2. Pick Neighbor.\n",
    "        try:\n",
    "            concept = to_concept(labeled, skip_trace=True)\n",
    "            new_data, metadata = example_sampler(concept)\n",
    "            dfa_dist[concept.dfa] = metadata['surprisal'] + concept.size / 100\n",
    "            new_data = LabeledExamples(\n",
    "                positive=frozenset(map(trace, new_data.positive)),\n",
    "                negative=frozenset(map(trace, new_data.negative)),\n",
    "            )\n",
    "            unlabeled |= new_data.positive | new_data.negative\n",
    "        except ConceptIdException:\n",
    "            break\n",
    "\n",
    "        # Compute neighbor energy and energy difference.\n",
    "        energy = metadata['surprisal'] + concept.size / 100\n",
    "        dE = energy - prev_energy\n",
    "            \n",
    "        # Accept/Reject based on energy delta.\n",
    "        if (dE > 0) and (np.exp(-dE/temp) < np.random.rand()):\n",
    "            energy = prev_energy\n",
    "        else:\n",
    "            labeled @= new_data\n",
    "            #view_pydot(get_dot(concept.dfa))\n",
    "\n",
    "        prev_energy= energy\n",
    "        \n",
    "    # 2. Compute CDF + Normalizer\n",
    "    sorted_dfas = sorted(list(dfa_dist), key=lambda x: dfa_dist[x])\n",
    "    Z1 = sum(np.exp(-x) for x in dfa_dist.values())\n",
    "    cdf = [0]\n",
    "    r = 0\n",
    "    for k, dfa_ in enumerate(sorted_dfas):\n",
    "        pdf = np.exp(-dfa_dist[dfa_]) / Z1\n",
    "        cdf.append(cdf[-1] + pdf)\n",
    "        if cdf[-1] > .8:\n",
    "            r = k\n",
    "\n",
    "    # 3. Compute distiguishing strings for top 80%.\n",
    "    for dfa1, dfa2 in combinations(sorted_dfas[:r], 2):\n",
    "        ce = find_equiv_counterexample(dfa1, dfa2)\n",
    "        unlabeled.add(ce)\n",
    "\n",
    "    # 4. Compute current support's belief on unlabeled strings of interest.\n",
    "    weighted_words = defaultdict(lambda: 0)\n",
    "    beta =  (1 - i / (n_iters)) + 0.01\n",
    "    Z2 = sum(np.exp(-x / beta) for x in dfa_dist.values())\n",
    "    for word in unlabeled:\n",
    "        for dfa_, energy in dfa_dist.items():\n",
    "            pdfa = np.exp(-energy / beta) / Z2\n",
    "            weighted_words[word] += pdfa * dfa_.label(word)\n",
    "\n",
    "    # 5. Restart based on marginalizing over current concept class.\n",
    "    positive, negative = set(), set()\n",
    "    for x, weight in weighted_words.items():\n",
    "        confidence = 2*(weight - 0.5 if weight > 0.5 else 0.5 - weight)\n",
    "        if np.random.rand() > confidence:\n",
    "            continue\n",
    "        if weight < 0.5:\n",
    "            negative.add(x)\n",
    "        elif weight > 0.5:\n",
    "            positive.add(x)\n",
    "    labeled = LabeledExamples(positive, negative)  \n",
    "\n",
    "\n",
    "    #continue  # Comment out to show live CDF\n",
    "    # Plot CDF of distribution.\n",
    "    sns.lineplot(x=list(range(len(cdf))), y=cdf)\n",
    "    plt.xlabel('DFA index (sorted by probability mass)')\n",
    "    plt.ylabel('CDF')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print('=====================================')\n",
    "print('   Predicting Labeled Examples       ')\n",
    "print('=====================================')\n",
    "positive, negative = set(), set()\n",
    "for x, weight in weighted_words.items():\n",
    "    if np.random.rand() > confidence:\n",
    "        continue\n",
    "    if weight < 0.2:\n",
    "        negative.add(x)\n",
    "    elif weight > 0.8:\n",
    "        positive.add(x)\n",
    "labeled = LabeledExamples(positive, negative)\n",
    "print(labeled)\n",
    "\n",
    "\n",
    "print('=====================================')\n",
    "print('          Top 50% of DFAs            ')\n",
    "print('=====================================')\n",
    "for dfa_, cd in zip(sorted_dfas, cdf[1:]):\n",
    "    if cd > 0.8:\n",
    "        break\n",
    "    view_pydot(get_dot(dfa_))\n",
    "    print(f'probability = {np.exp(-dfa_dist[dfa_]) / Z1:.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
