{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration Informed Specification Search: Experiment\n",
    "\n",
    "Let's take a look at how the DISS algorithm can search for specifications by leveraging expert demonstrations. \n",
    "We'll focus on learning DFAs in this case, but note that this approach is not confined to any specific concept class. To start consider an agent operating in the following stochastic gridworld."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure style=\"padding: 1em; background: #494949;\">\n",
    "    <img src=\"imgs/enter_lava_augmented_1.svg\"\n",
    "         style=\"height: 20em;\"\n",
    "     />\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Agent Actions\n",
    "\n",
    "The agent can attempt to move up, down, left, or right as illustrated below.\n",
    "\n",
    "<figure style=\"padding: 1em; background: #494949;\">\n",
    "    <img src=\"imgs/enter_lava_augmented_2.svg\"\n",
    "         style=\"height: 20em;\"\n",
    "     />\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Transitions\n",
    "\n",
    "However, there is some small probability that the agent will slip downward do to wind!\n",
    "\n",
    "<figure style=\"padding: 1em; background: #494949;\">\n",
    "    <img src=\"imgs/enter_lava_augmented_3.svg\"\n",
    "         style=\"height: 20em;\"\n",
    "     />\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's assume the agent's task can be described in terms of the color's of the tiles. **What was the agent trying to do?**\n",
    "\n",
    "\n",
    "## Probably avoiding the red tiles\n",
    "\n",
    "<figure style=\"padding: 1em; background: #494949;\">\n",
    "    <img src=\"imgs/enter_lava_augmented_4.svg\"\n",
    "         style=\"height: 20em;\"\n",
    "     />\n",
    "</figure>\n",
    "\n",
    "## Probably trying to reach yellow tile\n",
    "\n",
    "<figure style=\"padding: 1em; background: #494949;\">\n",
    "    <img src=\"imgs/enter_lava_augmented_5.svg\"\n",
    "         style=\"height: 20em;\"\n",
    "     />\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will illustrate learning task representations (in the form of Deterministic Finite Automata, i.e. DFA) that can be learned incrementally and describe temporal tasks.\n",
    "\n",
    "In particular, we shall consider a variation of the following gridworld from [this](https://mjvc.me/DISS/#/77) slide deck: Here the agent's task is a composition of three subtasks.\n",
    "\n",
    "<figure style=\"padding: 1em; background: #494949;\">\n",
    "    <img src=\"imgs/example_domain_1.svg\"\n",
    "         style=\"height: 20em;\"\n",
    "     />\n",
    "</figure>\n",
    "\n",
    "Where each subtask is a regular language represented as a DFA.\n",
    "\n",
    "<figure style=\"padding: 1em; background: #494949;\">\n",
    "    <img src=\"imgs/example_domain_2_1.svg\"\n",
    "         style=\"height: 20em;\"\n",
    "     />\n",
    "</figure>\n",
    "\n",
    "Further, we shall assume that the first two subtasks are a-priori known (say due to learning in another workspace), \n",
    "<figure style=\"padding: 1em; background: #494949;\">\n",
    "    <img src=\"imgs/example_domain_1_2.svg\"\n",
    "         style=\"height: 20em;\"\n",
    "     />\n",
    "</figure>\n",
    "\n",
    "and our task is to learn the third task given a partial demonstration.\n",
    "<figure style=\"padding: 1em; background: #494949;\">\n",
    "    <img src=\"imgs/example_domain_3_2.svg\"\n",
    "         style=\"height: 20em;\"\n",
    "     />\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "import attr\n",
    "import funcy as fn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bidict import bidict\n",
    "from IPython.display import Image, display\n",
    "import networkx as nx\n",
    "import pydot\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import dfa\n",
    "from dfa.utils import find_subset_counterexample, find_equiv_counterexample\n",
    "from dfa_identify import find_dfa, find_dfas\n",
    "\n",
    "from diss.product_mc import ProductMC\n",
    "from diss.dfa_concept import DFAConcept\n",
    "from diss.domains.gridworld_naive import GridWorldNaive as World\n",
    "from diss.domains.gridworld_naive import GridWorldState as State\n",
    "from diss import search, LabeledExamples, GradientGuidedSampler, ConceptIdException\n",
    "from pprint import pprint\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm.notebook import trange\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import HTML as html_print\n",
    "\n",
    "sns.set_context('paper')\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's first visualize our gridworld and a demonstration within the gridworld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_ALIAS = {\n",
    "    'yellow': '#ffff00', 'brown': '#ffb081',\n",
    "    'red': '#ff8b8b', 'blue': '#afafff', 'green' : '#67f7a1'\n",
    "}\n",
    "\n",
    "\n",
    "def tile(color='black'):\n",
    "    color = COLOR_ALIAS.get(color, color)\n",
    "    s = '&nbsp;'*4\n",
    "    return f\"<text style='border: solid 1px;background-color:{color}'>{s}</text>\"\n",
    "\n",
    "\n",
    "def ap_at_state(x, y, world):\n",
    "    \"\"\"Use sensor to create colored tile.\"\"\"\n",
    "    if (x, y) in world.overlay:\n",
    "        color = world.overlay[(x,y)]\n",
    "\n",
    "        if color in COLOR_ALIAS.keys():\n",
    "            return tile(color)\n",
    "    return tile('white')\n",
    "\n",
    "def print_map(world):\n",
    "    \"\"\"Scan the board row by row and print colored tiles.\"\"\"\n",
    "    order = range(1, world.dim + 1)\n",
    "    for y in order:\n",
    "        chars = (ap_at_state(x, y, world) for x in order)\n",
    "        display(html_print('&nbsp;'.join(chars)))\n",
    "\n",
    "def print_trc(trc, world, idx=0):\n",
    "    states = [s for s, kind in trc if kind == 'ego']\n",
    "    actions = [s.action for s, kind in trc if kind == 'env']\n",
    "\n",
    "    obs = [ap_at_state(pos.x, pos.y, world) for pos in states]\n",
    "    display(\n",
    "        html_print(f'trc {idx}:&nbsp;&nbsp;&nbsp;' + ''.join(''.join(x) for x in zip(obs, actions)) + '\\n')\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw = World(\n",
    "    dim=3,\n",
    "    start=State(x=3, y=1),\n",
    "    overlay={\n",
    "      (1, 1): 'yellow',\n",
    "      (1, 2): 'green',\n",
    "      (1, 3): 'green',\n",
    "      (2, 3): 'red',\n",
    "      (3, 2): 'blue',\n",
    "      (3, 3): 'blue',\n",
    "    }\n",
    ")\n",
    "\n",
    "demos = [[\n",
    "   (State(3, 1), 'ego'),\n",
    "   (State(3, 1, '←'), 'env'),\n",
    "   (State(3, 2), 'ego'),\n",
    "   (State(3, 2, '←'), 'env'),\n",
    "   (State(2, 2), 'ego'),\n",
    "   (State(2, 2, '←'), 'env'),\n",
    "   (State(1, 2), 'ego'),\n",
    "   (State(1, 2, '↑'), 'env'),\n",
    "   (State(1, 1), 'ego'),\n",
    "]]\n",
    "\n",
    "print_map(gw)\n",
    "print_trc(demos[0], gw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare against our target domain:\n",
    "\n",
    "<figure style=\"padding: 1em; background: #494949;\">\n",
    "    <img src=\"imgs/example_domain_3_2.svg\"\n",
    "         style=\"height: 20em;\"\n",
    "     />\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can define a set of expert demonstrations for this gridworld to guide our specification search procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with some very simple base examples to warm-start our specification search process. We want to synthesize a spec that's consistent with the observed evidence thus far:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going from the partial spec to a full spec :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_dfa(inputs):\n",
    "    def transition(s, c):\n",
    "        if c == 'red':\n",
    "            return s | 0b01\n",
    "        elif c == 'yellow':\n",
    "            return s | 0b10\n",
    "        return s\n",
    "\n",
    "    return dfa.DFA(\n",
    "        start=0b00,\n",
    "        inputs=inputs,\n",
    "        label=lambda s: s == 0b10,\n",
    "        transition=transition\n",
    "    )\n",
    "\n",
    "def ignore_white(path):\n",
    "    return tuple(x for x in path if x != 'white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can outline the machinery for the search process itself. We use the solution procedure in the DFA identification algorithm to synthesize a minimal DFA (in both states and non-stuttering edges) that is consistent with the observed examples to this point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fn.memoize(key_func=lambda accepting, rejecting, alphabet, order_by_stutter: hash((accepting, rejecting)))\n",
    "def find_dfas2(accepting, rejecting, alphabet, order_by_stutter):\n",
    "    dfas = find_dfas(accepting, rejecting, alphabet=alphabet, order_by_stutter=order_by_stutter)\n",
    "    dfas = fn.take(10, dfas)\n",
    "    return dfas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_check_wrapper(dfa_candidate):\n",
    "    partial = partial_dfa(dfa_candidate.inputs)\n",
    "    ce = find_subset_counterexample(dfa_candidate, partial)\n",
    "    return ce is None\n",
    "\n",
    "\n",
    "ALPHABET = frozenset({'red', 'yellow', 'blue', 'green'})\n",
    "\n",
    "base_examples = LabeledExamples(\n",
    "    positive=[\n",
    "        ('yellow',),\n",
    "        ('yellow', 'yellow'),\n",
    "    ],\n",
    "    negative=[\n",
    "        (), ('red',), ('red', 'red'),\n",
    "        ('red', 'yellow'), ('yellow', 'red'),\n",
    "        ('yellow', 'red', 'yellow'),\n",
    "        ('yellow', 'yellow', 'red'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "@fn.memoize\n",
    "def subset_cegis(data):\n",
    "    global base_examples\n",
    "\n",
    "    for i in range(20):\n",
    "        mydfa = find_dfa(data.positive, data.negative, order_by_stutter=True) \n",
    "        if mydfa is None:\n",
    "            raise ConceptIdException\n",
    "        partial = partial_dfa(mydfa.inputs)\n",
    "        ce = find_subset_counterexample(mydfa, partial)\n",
    "        if ce is None:\n",
    "            break\n",
    "        base_examples @= LabeledExamples(negative=[ce])\n",
    "        data @= LabeledExamples(negative=[ce])\n",
    "\n",
    "        for k, lbl in enumerate(partial.transduce(ce)):\n",
    "            prefix = ce[:k]\n",
    "            if not lbl:\n",
    "                base_examples @= LabeledExamples(negative=[prefix])\n",
    "                data @= LabeledExamples(negative=[prefix])\n",
    "    return data\n",
    "\n",
    "\n",
    "def to_concept(data):\n",
    "    global base_examples\n",
    "    \n",
    "    data = data.map(ignore_white) @ base_examples\n",
    "    data = subset_cegis(data)\n",
    "\n",
    "    concept = DFAConcept.from_examples(data, subset_check_wrapper, alphabet=ALPHABET, find_dfas=find_dfas2) \n",
    "    # Adjust size to account for subset information.\n",
    "    return attr.evolve(concept, size=concept.size - np.log(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diss.dfa_concept import remove_stutter\n",
    "from collections import defaultdict\n",
    "\n",
    "# adapted from the dfa library\n",
    "def get_dot(dfa_):\n",
    "    dfa_dict, init = dfa.dfa2dict(dfa_)\n",
    "    remove_stutter(dfa_dict)\n",
    "    g = pydot.Dot(rankdir=\"LR\")\n",
    "\n",
    "    nodes = {}\n",
    "    for i, (k, (v, _)) in enumerate(dfa_dict.items()):\n",
    "        shape = \"doublecircle\" if v else \"circle\"\n",
    "        nodes[k] = pydot.Node(i+1, label=f\"{k}\", shape=shape)\n",
    "        g.add_node(nodes[k])\n",
    "\n",
    "    edges = defaultdict(list)\n",
    "    for start, (_, transitions) in dfa_dict.items():        \n",
    "        for action, end in transitions.items():\n",
    "            color = COLOR_ALIAS[str(action)]\n",
    "            edges[start, end].append(color)\n",
    "    \n",
    "    init_node = pydot.Node(0, shape=\"point\", label=\"\")\n",
    "    g.add_node(init_node)\n",
    "    g.add_edge(pydot.Edge(init_node, nodes[init]))\n",
    "\n",
    "    for (start, end), colors in edges.items():\n",
    "        for color in colors:\n",
    "            g.add_edge(pydot.Edge(nodes[start], nodes[end], label='⬛', fontcolor=color))\n",
    "            \n",
    "    return g\n",
    "\n",
    "def view_pydot(pdot):\n",
    "    plt = Image(pdot.create_png())\n",
    "    display(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated Annealed + SGGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diss import diss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fn.memoize(key_func=lambda c, t, psat: c.dfa)\n",
    "def to_chain(c, t, psat):\n",
    "    chain = ProductMC.construct(\n",
    "        concept=c, tree=t, dyn=gw, max_depth=9,\n",
    "        psat=0.8, sensor=gw.sensor\n",
    "    )\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_iters = 50\n",
    "\n",
    "\n",
    "dfa_search = diss(\n",
    "    demos=demos,\n",
    "    to_concept=to_concept,\n",
    "    to_chain=to_chain,\n",
    "    competency=lambda *_: 0.8,\n",
    "    lift_path=lambda x: ignore_white(map(gw.sensor, x)),\n",
    "    n_iters=n_iters,\n",
    "    reset_period=5,\n",
    "    surprise_weight=20,  # Rescale surprise to make comparable to size.\n",
    "    cmf_threshold=0.99,\n",
    ")\n",
    "\n",
    "concept2energy = {}\n",
    "for _, (data, concept, metadata) in zip(trange(n_iters, desc='DISS'), dfa_search):\n",
    "    concept2energy[concept] = metadata['energy']\n",
    "    poi = metadata['poi']\n",
    "    #view_pydot(get_dot(concept.dfa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sorted_concepts = sorted(list(concept2energy), key=concept2energy.get)\n",
    "pmf = np.array([np.exp(-concept2energy[c]) for c in sorted_concepts])\n",
    "Z = pmf.sum()\n",
    "print(f'{Z=}')\n",
    "pmf /= Z\n",
    "cmf = np.cumsum(pmf)\n",
    "idx = (cmf < 0.99).sum()  # 99% of probability mass concentrated below this point.\n",
    "\n",
    "for p, c in zip(pmf, sorted_concepts[:idx + 1]):\n",
    "    print(f'prob = {p:.3}')\n",
    "    print(f'energy = {concept2energy[c]:.3}')\n",
    "    print(f'size = {c.size:.3}')\n",
    "    view_pydot(get_dot(c.dfa))\n",
    "\n",
    "# Plot CDF of distribution.\n",
    "sns.lineplot(x=list(range(len(cmf))), y=cmf)\n",
    "plt.xlabel('DFA index (sorted by probability mass)')\n",
    "plt.ylabel('CMF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Compute current support's belief on unlabeled strings of interest.\n",
    "p_accept = {}\n",
    "for word in poi:\n",
    "    votes = np.array([(word in c) for c in sorted_concepts])\n",
    "    p_accept[word] = pmf @ votes\n",
    "    \n",
    "sorted_poi = sorted(poi, key=lambda x: -p_accept[x])\n",
    "\n",
    "for word in sorted_poi:\n",
    "    print(f'{word}'.ljust(50) + f'{p_accept[word]:.2}')\n",
    "    print('-' * 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepting, rejecting = set(), set()\n",
    "for word in poi:\n",
    "    belief = p_accept[word]\n",
    "    if belief > 0.9:\n",
    "        accepting.add(word)\n",
    "    elif belief < 0.1:\n",
    "        rejecting.add(word)\n",
    "data = LabeledExamples(accepting, rejecting)\n",
    "view_pydot(get_dot(to_concept(data).dfa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enumeration baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampler_factory(demos):\n",
    "    return GradientGuidedSampler.from_demos(\n",
    "        demos=demos,\n",
    "        to_chain=to_chain,\n",
    "        competency=lambda *_: 0.8,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_chain.invalidate_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dfa.utils import minimize\n",
    "\n",
    "def enumerate_dfas():\n",
    "    data = LabeledExamples(\n",
    "        positive=[\n",
    "            ('yellow',),\n",
    "            ('yellow', 'yellow'),\n",
    "        ],\n",
    "        negative=[\n",
    "            (), ('red',), ('red', 'red'),\n",
    "            ('red', 'yellow'), ('yellow', 'red'),\n",
    "            ('yellow', 'red', 'yellow'),\n",
    "            ('yellow', 'yellow', 'red'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # CEGIS loop to add constraints to enforce subsets.\n",
    "    for i in range(20):\n",
    "        tests = fn.take(5, find_dfas(\n",
    "            data.positive,\n",
    "            data.negative,\n",
    "            order_by_stutter=True,\n",
    "            allow_unminimized=True,\n",
    "        ))\n",
    "        new_data = LabeledExamples()\n",
    "        for test in tests:\n",
    "            assert test is not None\n",
    "            partial = partial_dfa(test.inputs)\n",
    "            ce = find_subset_counterexample(test, partial)\n",
    "            if ce is not None:\n",
    "                new_data @= LabeledExamples(negative=[ce])\n",
    "            if new_data.size == 0:\n",
    "                break\n",
    "\n",
    "        dfas = find_dfas(\n",
    "            data.positive,\n",
    "            data.negative,\n",
    "            order_by_stutter=True,\n",
    "            alphabet=ALPHABET,\n",
    "            allow_unminimized=True,\n",
    "        )\n",
    "        \n",
    "        yield from map(minimize, filter(subset_check_wrapper, dfas))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sggs = sampler_factory(demos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Z2 = 0\n",
    "dist = Counter()\n",
    "for i, d in enumerate(fn.distinct(enumerate_dfas())):\n",
    "    concept = DFAConcept.from_dfa(d)\n",
    "    dist.update([len(d.states())])\n",
    "    print(dist)\n",
    "    print(f'             {i}                ')\n",
    "    #energy = 10 * sggs(concept)[1]['surprisal'] + concept.size\n",
    "    #Z2 += np.exp(-energy)\n",
    "    \n",
    "    #print(f'{energy=:.3}')\n",
    "    #print(f'Z2 / Z = {Z2 / Z:0.3}')\n",
    "    print('--------------------------------')\n",
    "    if len(d.states()) > 4:\n",
    "        break\n",
    "    #view_pydot(get_dot(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circuit + BDD based MaxEnt Policy (CAV '20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create Dynamical System\n",
    "\n",
    "Here we create a BitVector sequential circuit, `DYN`, using `py-aiger`, the models a gridworld (line 4).\n",
    "\n",
    "Afterwords, lines 6-8 describe introducing a slip probability of `1/32` (modeled by a biased coin with bias `31/32`). \n",
    "\n",
    "**Note that states are 1-hot encoded**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiger as A\n",
    "import aiger_bv as BV\n",
    "import aiger_gridworld as GW\n",
    "import aiger_ptltl as LTL\n",
    "from bidict import bidict\n",
    "from aiger_bdd import to_bdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE = BV.uatom(16, 'state')\n",
    "X = STATE[:8]\n",
    "Y = STATE[8:]\n",
    "s0 = (3, 5)\n",
    "#                            \n",
    "DYN = GW.gridworld(8, start=(s0[0], 9 - s0[1]), compressed_inputs=True)\n",
    "SLIP = BV.atom(1, 'c', signed=False).repeat(2) & BV.atom(2, 'a', signed=False)\n",
    "SLIP = SLIP.with_output('a').aigbv\n",
    "DYN <<= SLIP\n",
    "\n",
    "def encode_state(x, y):\n",
    "    x, y = x - 1, (9 - y) + 7\n",
    "    return {'state': (1 << x) | (1 << y)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GW.GridState(encode_state(5, 4)['state'], 8).y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DYN.latch2init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DYN({'a': GW.WEST, 'c': 0})[0]['state'].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DYN({'a': GW.WEST, 'c': 1})[0]['state'].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin(encode_state(2, 3)['state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create Sensor / Feature overlay\n",
    "\n",
    "Next, we define the mapping from concrete states to sensor values / atomic predicates.\n",
    "We use simple coordinate wise bitvector masks to encode the color overlays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_test(xmask, ymask):\n",
    "    return ((X & xmask) !=0) & ((Y & ymask) != 0)\n",
    "\n",
    "\n",
    "APS = {       #            x-axis       y-axis\n",
    "    'yellow': mask_test(0b1000_0001, 0b1000_0001),\n",
    "    'blue':   mask_test(0b0001_1000, 0b0011_1000),\n",
    "    'brown':  mask_test(0b0011_1100, 0b1000_0001),\n",
    "    'red':    mask_test(0b1000_0001, 0b0011_0010) \\\n",
    "            | mask_test(0b0100_0010, 0b0011_0011),\n",
    "}\n",
    "0b0100_1100\n",
    "0b0011_0010\n",
    "def create_sensor(aps):\n",
    "    sensor = BV.aig2aigbv(A.empty())\n",
    "    for name, ap in APS.items():\n",
    "        sensor |= ap.with_output(name).aigbv\n",
    "    return sensor\n",
    "\n",
    "SENSOR = create_sensor(APS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Overlay\n",
    "\n",
    "This can all seem pretty abstract, so let's visualize the way the sensor sees the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML as html_print\n",
    "\n",
    "\n",
    "COLOR_ALIAS = {\n",
    "    'yellow': '#ffff8c', 'brown': '#ffb081',\n",
    "    'red': '#ff5454', 'blue': '#9595ff'\n",
    "}\n",
    "\n",
    "\n",
    "def tile(color='black'):\n",
    "    color = COLOR_ALIAS.get(color, color)\n",
    "    s = '&nbsp;'*4\n",
    "    return f\"<text style='border: solid 1px;background-color:{color}'>{s}</text>\"\n",
    "\n",
    "\n",
    "def ap_at_state(x, y, in_ascii=False):\n",
    "    \"\"\"Use sensor to create colored tile.\"\"\"\n",
    "    state = encode_state(x, y)\n",
    "    obs = SENSOR(state)[0]   # <----------   \n",
    "\n",
    "    for k in COLOR_ALIAS.keys():\n",
    "        if obs[k][0]:\n",
    "            return tile(k)\n",
    "    return tile('white')\n",
    "\n",
    "def print_map():\n",
    "    \"\"\"Scan the board row by row and print colored tiles.\"\"\"\n",
    "    order = range(1, 9)\n",
    "    for y in order:\n",
    "        chars = (ap_at_state(x, y, in_ascii=True) for x in order)\n",
    "        display(html_print('&nbsp;'.join(chars)))\n",
    "        \n",
    "print_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Describe demonstrations\n",
    "\n",
    "We now encode a collection of demonstrations from an agent attempting to:\n",
    "\n",
    "1. Avoid the red tiles (lava).\n",
    "2. Reach the yellow tiles (recharge).\n",
    "3. If the agent touches a blue tile (water), then it must dry off (brown tile) before recharging.\n",
    "\n",
    "**Note** Trace 5 corresponds to a very unlikely demonstration where the agent enters the water, but is unable to dry off due to wind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trc(trc, idx=0):\n",
    "    actions, states = trc\n",
    "    obs = (ap_at_state(*pos, in_ascii=True) for pos in states)\n",
    "    display(\n",
    "        html_print(f'trc {idx}:&nbsp;&nbsp;&nbsp;' + ''.join(''.join(x) for x in zip(actions, obs)) + '\\n')\n",
    "    )\n",
    "\n",
    "ACTIONS0 = \"→→↑↑↑↑→→→\"\n",
    "STATES0 = ((4, 5), (5, 5), (5, 4), (5, 3),(5, 2), (5, 1), (6, 1), (7, 1), (8, 1))\n",
    "TRC0 = (ACTIONS0, STATES0)\n",
    "print_trc(TRC0, 0)\n",
    "\n",
    "ACTIONS1 = \"↑↑↑↑←←←←←\"\n",
    "STATES1 = ((3, 4), (3, 3), (3, 2), (3, 1), (2, 1), (1, 1), (1, 1), (1, 1), (1, 1),)\n",
    "TRC1 = (ACTIONS1, STATES1)\n",
    "print_trc(TRC1, 1)\n",
    "\n",
    "ACTIONS2 = \"←→↑↑↑←↑←←\"\n",
    "STATES2 = ((2, 5), (3, 5), (3, 4), (3, 3), (3, 2), (2, 2), (2, 1), (1, 1), (1, 1))\n",
    "TRC2 = (ACTIONS2, STATES2)\n",
    "print_trc(TRC2, 2)\n",
    "\n",
    "ACTIONS3 = \"↑↑→←↑↑←←←\"\n",
    "STATES3 = ((3, 4), (3, 3), (4, 3), (3, 3), (3, 2), (3, 1), (2, 1), (1, 1), (1, 1))\n",
    "TRC3 = (ACTIONS3, STATES3)\n",
    "print_trc(TRC3, 3)\n",
    "\n",
    "ACTIONS4 = \"↑→↑↑↑←←←←\"\n",
    "STATES4 = ((3, 4), (4, 4), (4, 3), (4, 2), (4, 1), (3, 1), (2, 1), (1, 1), (1, 1))\n",
    "TRC4 = (ACTIONS4, STATES4)\n",
    "print_trc(TRC4, 4)\n",
    "\n",
    "ACTIONS5 = \"↑→↑↑→→→→→\"\n",
    "STATES5 = ((3, 4), (4, 4), (4, 3), (4, 2), (3, 2), (2, 2), (1, 2), (1, 2), (1, 2))\n",
    "TRC5 = (ACTIONS5, STATES5)\n",
    "print_trc(TRC5, 5)\n",
    "\n",
    "TRACES = [TRC0, TRC1, TRC2, TRC3, TRC4]         # Variety of positive demos.\n",
    "TRACES += [TRC5]                                # Unlucky, Negative Demonstration.\n",
    "TRACES += 4 * [TRC4]                            # Additional \"Safe\" Demonstrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_trace(trc):\n",
    "    actions, states = trc\n",
    "    actions = [{'a': a} for a in actions]\n",
    "    states = [encode_state(*s) for s in states]\n",
    "\n",
    "    \n",
    "    for s, a, s2 in zip([encode_state(*s0)] + states, actions, states):\n",
    "        s, s2 = GW.GridState(s['state'], 8), GW.GridState(s2['state'], 8)\n",
    "        action = a['a']\n",
    "        print((s.x, s.y), (s2.x, s2.y), action)\n",
    "        if action == GW.WEST:\n",
    "            a['c'] = 1\n",
    "        elif action == GW.EAST:\n",
    "            a['c'] = int((s2.x > s.x) or s.x == 8)\n",
    "        else:\n",
    "\n",
    "\n",
    "            #print(s.x, s2.x, action)\n",
    "\n",
    "            a['c'] = int(s.x == s2.x)\n",
    "    actions[-1]['c'] = 1  # Last action needs some arbitrary assignment to slipping.\n",
    "    \n",
    "    return actions, states\n",
    "\n",
    "encode_trace(TRC5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define Specification Circuits / Concept Class\n",
    "\n",
    "First, we describe the properties over colors of the map. This is done in past tense temporal logic using `py-aiger-ptltl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAVA, RECHARGE, WATER, DRY = map(LTL.atom, ['red', 'yellow', 'blue', 'brown'])\n",
    "\n",
    "EVENTUALLY_RECHARGE = RECHARGE.once()\n",
    "AVOID_LAVA = (~LAVA).historically()\n",
    "\n",
    "RECHARGED_AND_ONCE_WET = RECHARGE & WATER.once()\n",
    "DRIED_OFF = (~WATER).since(DRY)\n",
    "\n",
    "DIDNT_RECHARGE_WHILE_WET = (RECHARGED_AND_ONCE_WET).implies(DRIED_OFF)\n",
    "DONT_RECHARGE_WHILE_WET = DIDNT_RECHARGE_WHILE_WET.historically()\n",
    "\n",
    "CONST_TRUE = LTL.atom(True)\n",
    "\n",
    "\n",
    "SPECS = [\n",
    "    CONST_TRUE, AVOID_LAVA, EVENTUALLY_RECHARGE, DONT_RECHARGE_WHILE_WET,\n",
    "    AVOID_LAVA & EVENTUALLY_RECHARGE & DONT_RECHARGE_WHILE_WET,\n",
    "    AVOID_LAVA & EVENTUALLY_RECHARGE,\n",
    "    AVOID_LAVA & DONT_RECHARGE_WHILE_WET,\n",
    "    EVENTUALLY_RECHARGE & DONT_RECHARGE_WHILE_WET,\n",
    "]\n",
    "\n",
    "SPEC_NAMES = [\n",
    "    \"CONST_TRUE\", \"AVOID_LAVA\", \"EVENTUALLY_RECHARGE\", \"DONT_RECHARGE_WHILE_WET\",\n",
    "    \"AVOID_LAVA & EVENTUALLY_RECHARGE & DONT_RECHARGE_WHILE_WET\",\n",
    "    \"AVOID_LAVA & EVENTUALLY_RECHARGE\",\n",
    "    \"AVOID_LAVA & DONT_RECHARGE_WHILE_WET\",\n",
    "    \"EVENTUALLY_RECHARGE & DONT_RECHARGE_WHILE_WET\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec2monitor(spec):\n",
    "    spec = spec.with_output('SAT')\n",
    "    monitor = spec.aig | A.sink(['red', 'yellow', 'brown', 'blue'])\n",
    "    monitor = BV.aig2aigbv(monitor)\n",
    "    return DYN >> SENSOR >> monitor\n",
    "    \n",
    "SPEC2MONITORS = { spec: spec2monitor(spec) for spec in SPECS }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating BDD game-graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec2monitor(SPECS[4]).simulate(encode_trace(TRC4)[0])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrolled = spec2monitor(SPECS[4]).aigbv \\\n",
    "                                 .cone('SAT') \\\n",
    "                                 .unroll(10, only_last_outputs=True)\n",
    "causal_order = []\n",
    "for t in range(10):\n",
    "    causal_order.append(f'a##time_{t}[0]')\n",
    "    causal_order.append(f'a##time_{t}[1]')\n",
    "    causal_order.append(f'c##time_{t}[0]')\n",
    "causal_order = {x: i for i, x in enumerate(causal_order)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dd.cudd import BDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = BDD()\n",
    "manager.declare(*causal_order)\n",
    "bexpr, *_ = to_bdd(unrolled, manager=manager, renamer=lambda _, x: x, levels=causal_order)\n",
    "bexpr.dag_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(manager.vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_nx(bexpr):\n",
    "    # DFS to translate edge-compelemented BDD to networkx graph.\n",
    "    dag = nx.DiGraph()\n",
    "\n",
    "    stack, visited = [(bexpr, False, int(bexpr))], set()\n",
    "    while stack:\n",
    "        bexpr, parity, ref = stack.pop()\n",
    "\n",
    "        if ref in visited:\n",
    "            continue\n",
    "\n",
    "        visited.add(ref)\n",
    "        if bexpr in (bexpr.bdd.true, bexpr.bdd.false):\n",
    "            label = bexpr == bexpr.bdd.true\n",
    "            dag.add_node(ref, label=label, level=len(bexpr.bdd.vars))\n",
    "            continue\n",
    "\n",
    "        dag.add_node(ref, label=bexpr.var, level=bexpr.level)\n",
    "\n",
    "        parity = bexpr.negated ^ parity\n",
    "        for lbl, bexpr2 in [(0, bexpr.low), (1, bexpr.high)]:\n",
    "            ref2 = int(bexpr2 if parity else ~bexpr2)\n",
    "            dag.add_edge(ref, ref2, label=lbl)\n",
    "            stack.append((bexpr2, parity, ref2))\n",
    "    return dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dag = to_nx(bexpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dag.neighbors(int(bexpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for src, data in dag.nodes(data=True):\n",
    "    label = data['label']\n",
    "    if isinstance(label, bool):\n",
    "        data['kind'] = label\n",
    "    elif label.startswith('a'):\n",
    "        data['kind'] = 'ego'\n",
    "    else:\n",
    "        data['kind'] = 'env'\n",
    "\n",
    "for src, tgt, data in dag.edges(data=True):\n",
    "    entropy = dag.nodes[tgt]['level'] - dag.nodes[src]['level'] - 1\n",
    "    entropy /= np.log2(np.e)  # Convert from base 2.\n",
    "    data['entropy'] = entropy\n",
    "    \n",
    "    if dag.nodes[src]['kind'] == 'env':\n",
    "        data['prob'] = 31/32 if data['label'] else 1/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dag.nodes[int(bexpr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diss.tabular import TabularPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TabularPolicy.from_psat(dag, psat=0.92).psat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
